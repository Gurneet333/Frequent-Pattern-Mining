{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>\n",
    "    \n",
    "**(Implementation project) Using a programming language that you are familiar with, such as C++ or Java, implement three frequent itemset mining algorithms introduced in this chapter: (1) Apriori [AS94b], (2) FP-growth [HPY00],** \n",
    " \n",
    " </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apriori Function\n",
    "\n",
    "This is the main function of this Apriori Python implementation. The most important part of this function is from line 16 ~ line 21. It basically follows my modified pseudocode written above.\n",
    "\n",
    "1. Generate the candidate set by joining the frequent itemset from the previous stage.\n",
    "\n",
    "2. Perform subset testing and prune the candidate set if thereâ€™s an infrequent itemset contained.\n",
    "\n",
    "3. Calculate the final frequent itemset by getting those satisfy minimum support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain, combinations\n",
    "\n",
    "def apriori(itemSetList, minSup, minConf):\n",
    "    C1ItemSet = getItemSetFromList(itemSetList)\n",
    "    # Final result, global frequent itemset\n",
    "    globalFreqItemSet = dict()\n",
    "    # Storing global itemset with support count\n",
    "    globalItemSetWithSup = defaultdict(int)\n",
    "\n",
    "    L1ItemSet = getAboveMinSup(C1ItemSet, itemSetList, minSup, globalItemSetWithSup)\n",
    "    currentLSet = L1ItemSet\n",
    "    k = 2\n",
    "\n",
    "    # Calculating frequent item set\n",
    "    while(currentLSet):\n",
    "        # Storing frequent itemset\n",
    "        globalFreqItemSet[k-1] = currentLSet\n",
    "        # Self-joining Lk\n",
    "        candidateSet = getUnion(currentLSet, k)\n",
    "        # Perform subset testing and remove pruned supersets\n",
    "        candidateSet = pruning(candidateSet, currentLSet, k-1)\n",
    "        # Scanning itemSet for counting support\n",
    "        currentLSet = getAboveMinSup(candidateSet, itemSetList, minSup, globalItemSetWithSup)\n",
    "        k += 1\n",
    "\n",
    "    #rules = associationRule(globalFreqItemSet, globalItemSetWithSup, minConf)\n",
    "    #rules.sort(key=lambda x: x[2])\n",
    "\n",
    "    return globalFreqItemSet, rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Candidate Generation\n",
    "\n",
    "For self-joining, we simply get all the union through brute-force and only return those are in the specific length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUnion(itemSet, length):\n",
    "    return set([i.union(j) for i in itemSet for j in itemSet if len(i.union(j)) == length])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning\n",
    "\n",
    "To perform subset testing, we loop through all possible subsets in the itemset. If the subset is not in the previous frequent itemset, we prune it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruning(candidateSet, prevFreqSet, length):\n",
    "    tempCandidateSet = candidateSet.copy()\n",
    "    for item in candidateSet:\n",
    "        subsets = combinations(item, length)\n",
    "        for subset in subsets:\n",
    "            # if the subset is not in previous K-frequent get, then remove the set\n",
    "            if(frozenset(subset) not in prevFreqSet):\n",
    "                tempCandidateSet.remove(item)\n",
    "                break\n",
    "    return tempCandidateSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Frequent Itemset from Candidate\n",
    "\n",
    "In the final step, we turn the candidate sets into frequent itemsets. Since we are not applying any improvement technique. The only approach we can go for is to brainlessly loop through the item and itemset over and over again to obtain the count. At last, we only retain the itemsets whose support is equal or higher than minimum support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAboveMinSup(itemSet, itemSetList, minSup, globalItemSetWithSup):\n",
    "    freqItemSet = set()\n",
    "    localItemSetWithSup = defaultdict(int)\n",
    "\n",
    "    for item in itemSet:\n",
    "        for itemSet in itemSetList:\n",
    "            if item.issubset(itemSet):\n",
    "                globalItemSetWithSup[item] += 1\n",
    "                localItemSetWithSup[item] += 1\n",
    "\n",
    "    for item, supCount in localItemSetWithSup.items():\n",
    "        support = float(supCount / len(itemSetList))\n",
    "        if(support >= minSup):\n",
    "            freqItemSet.add(item)\n",
    "\n",
    "    return freqItemSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the itemset from the list\n",
    "def getItemSetFromList(itemSetList):\n",
    "    tempItemSet = set()\n",
    "\n",
    "    for itemSet in itemSetList:\n",
    "        for item in itemSet:\n",
    "            tempItemSet.add(frozenset([item]))\n",
    "\n",
    "    return tempItemSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def associationRule(freqItemSet, itemSetWithSup, minConf):\n",
    "    rules = []\n",
    "    for k, itemSet in freqItemSet.items():\n",
    "        for item in itemSet:\n",
    "            subsets = powerset(item)\n",
    "            for s in subsets:\n",
    "                confidence = float(\n",
    "                    itemSetWithSup[item] / itemSetWithSup[frozenset(s)])\n",
    "                if(confidence > minConf):\n",
    "                    rules.append([set(s), set(item.difference(s)), confidence])\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(s):\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1, len(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {frozenset({'soup'}), frozenset({'eggs'}), frozenset({'bacon'})}, 2: {frozenset({'bacon', 'eggs'}), frozenset({'bacon', 'soup'})}}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "itemSetList = [['eggs', 'bacon', 'soup'],\n",
    "                ['eggs', 'bacon', 'apple'],\n",
    "                ['soup', 'bacon', 'banana']]\n",
    "freqItemSet, rules = apriori(itemSetList, minSup=0.5, minConf=0.5)\n",
    "print(freqItemSet)\n",
    "print(rules) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {frozenset({'O'}), frozenset({'K'}), frozenset({'Y'}), frozenset({'M'}), frozenset({'E'})}, 2: {frozenset({'O', 'E'}), frozenset({'K', 'O'}), frozenset({'K', 'Y'}), frozenset({'K', 'E'}), frozenset({'K', 'M'})}, 3: {frozenset({'K', 'O', 'E'})}}\n"
     ]
    }
   ],
   "source": [
    "itemSetList1 = [['M', 'O', 'N','K','E','Y'],\n",
    "                ['D', 'O', 'N','K','E','Y'],\n",
    "                ['M', 'O', 'N','K','E','Y'],\n",
    "                ['M', 'A','K','E'],\n",
    "                ['M', 'U','C','K','Y'],\n",
    "                ['C', 'O','O','K','I','E']\n",
    "              ]\n",
    "freqItemSet1, rules1 = apriori(itemSetList1, minSup=0.6, minConf=0.8)\n",
    "print(freqItemSet1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'K'}, {'E'}, 0.8333333333333334],\n",
       " [{'O'}, {'E'}, 1.0],\n",
       " [{'O'}, {'K'}, 1.0],\n",
       " [{'Y'}, {'K'}, 1.0],\n",
       " [{'E'}, {'K'}, 1.0],\n",
       " [{'M'}, {'K'}, 1.0],\n",
       " [{'O'}, {'E', 'K'}, 1.0],\n",
       " [{'K', 'O'}, {'E'}, 1.0],\n",
       " [{'E', 'O'}, {'K'}, 1.0]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rules1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "colnames=['age','workclass','fnlwgt',\n",
    "'education', 'education-num','marital-status', 'occupation', 'relationship','race','sex','capital-gain','capital-loss','hours-per-week',\n",
    "'native-country','Salary'] \n",
    "\n",
    "itemSetList1 =pd.read_csv(\"testr.csv\", names=colnames, header=None)\n",
    "\n",
    "#freqItemSet1, rules1 = apriori(itemSetList1, minSup=0.6, minConf=0.8)\n",
    "#print(freqItemSet1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education-num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital-gain  capital-loss  hours-per-week  native-country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "       Salary  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32556   <=50K  \n",
       "32557    >50K  \n",
       "32558   <=50K  \n",
       "32559   <=50K  \n",
       "32560    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemSetList1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'observations = [] \\nfor i in range(len(itemSetList1)):\\n    observations.append([str(itemSetList1.values[i,j]) for j in range(15)])'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''observations = [] \n",
    "for i in range(len(itemSetList1)):\n",
    "    observations.append([str(itemSetList1.values[i,j]) for j in range(15)])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "Description     : Simple Python implementation of the Apriori Algorithm\n",
    "\n",
    "Usage:\n",
    "    $python apriori.py -f DATASET.csv -s minSupport  -c minConfidence\n",
    "\n",
    "    $python apriori.py -f DATASET.csv -s 0.15 -c 0.6\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser\n",
    "\n",
    "\n",
    "def subsets(arr):\n",
    "    \"\"\" Returns non empty subsets of arr\"\"\"\n",
    "    return chain(*[combinations(arr, i + 1) for i, a in enumerate(arr)])\n",
    "\n",
    "\n",
    "def returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet):\n",
    "    \"\"\"calculates the support for items in the itemSet and returns a subset\n",
    "    of the itemSet each of whose elements satisfies the minimum support\"\"\"\n",
    "    _itemSet = set()\n",
    "    localSet = defaultdict(int)\n",
    "\n",
    "    for item in itemSet:\n",
    "        for transaction in transactionList:\n",
    "            if item.issubset(transaction):\n",
    "                freqSet[item] += 1\n",
    "                localSet[item] += 1\n",
    "\n",
    "    for item, count in localSet.items():\n",
    "        support = float(count) / len(transactionList)\n",
    "\n",
    "        if support >= minSupport:\n",
    "            _itemSet.add(item)\n",
    "\n",
    "    return _itemSet\n",
    "\n",
    "\n",
    "def joinSet(itemSet, length):\n",
    "    \"\"\"Join a set with itself and returns the n-element itemsets\"\"\"\n",
    "    return set(\n",
    "        [i.union(j) for i in itemSet for j in itemSet if len(i.union(j)) == length]\n",
    "    )\n",
    "\n",
    "\n",
    "def getItemSetTransactionList(data_iterator):\n",
    "    transactionList = list()\n",
    "    itemSet = set()\n",
    "    for record in data_iterator:\n",
    "        transaction = frozenset(record)\n",
    "        transactionList.append(transaction)\n",
    "        for item in transaction:\n",
    "            itemSet.add(frozenset([item]))  # Generate 1-itemSets\n",
    "    return itemSet, transactionList\n",
    "\n",
    "\n",
    "def runApriori(data_iter, minSupport, minConfidence):\n",
    "    \"\"\"\n",
    "    run the apriori algorithm. data_iter is a record iterator\n",
    "    Return both:\n",
    "     - items (tuple, support)\n",
    "     - rules ((pretuple, posttuple), confidence)\n",
    "    \"\"\"\n",
    "    itemSet, transactionList = getItemSetTransactionList(data_iter)\n",
    "\n",
    "    freqSet = defaultdict(int)\n",
    "    largeSet = dict()\n",
    "    # Global dictionary which stores (key=n-itemSets,value=support)\n",
    "    # which satisfy minSupport\n",
    "\n",
    "    assocRules = dict()\n",
    "    # Dictionary which stores Association Rules\n",
    "\n",
    "    oneCSet = returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet)\n",
    "\n",
    "    currentLSet = oneCSet\n",
    "    k = 2\n",
    "    while currentLSet != set([]):\n",
    "        largeSet[k - 1] = currentLSet\n",
    "        currentLSet = joinSet(currentLSet, k)\n",
    "        currentCSet = returnItemsWithMinSupport(\n",
    "            currentLSet, transactionList, minSupport, freqSet\n",
    "        )\n",
    "        currentLSet = currentCSet\n",
    "        k = k + 1\n",
    "\n",
    "    def getSupport(item):\n",
    "        \"\"\"local function which Returns the support of an item\"\"\"\n",
    "        return float(freqSet[item]) / len(transactionList)\n",
    "\n",
    "    toRetItems = []\n",
    "    for key, value in largeSet.items():\n",
    "        toRetItems.extend([(tuple(item), getSupport(item)) for item in value])\n",
    "\n",
    "    toRetRules = []\n",
    "    for key, value in list(largeSet.items())[1:]:\n",
    "        for item in value:\n",
    "            _subsets = map(frozenset, [x for x in subsets(item)])\n",
    "            for element in _subsets:\n",
    "                remain = item.difference(element)\n",
    "                if len(remain) > 0:\n",
    "                    confidence = getSupport(item) / getSupport(element)\n",
    "                    if confidence >= minConfidence:\n",
    "                        toRetRules.append(((tuple(element), tuple(remain)), confidence))\n",
    "    return toRetItems, toRetRules\n",
    "\n",
    "\n",
    "def printResults(items, rules):\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    for item, support in sorted(items, key=lambda x: x[1]):\n",
    "        print(\"item: %s , %.3f\" % (str(item), support))\n",
    "    print(\"\\n------------------------ RULES:\")\n",
    "    for rule, confidence in sorted(rules, key=lambda x: x[1]):\n",
    "        pre, post = rule\n",
    "        print(\"Rule: %s ==> %s , %.3f\" % (str(pre), str(post), confidence))\n",
    "\n",
    "\n",
    "def to_str_results(items, rules):\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    i, r = [], []\n",
    "    for item, support in sorted(items, key=lambda x: x[1]):\n",
    "        x = \"item: %s , %.3f\" % (str(item), support)\n",
    "        i.append(x)\n",
    "\n",
    "    for rule, confidence in sorted(rules, key=lambda x: x[1]):\n",
    "        pre, post = rule\n",
    "        x = \"Rule: %s ==> %s , %.3f\" % (str(pre), str(post), confidence)\n",
    "        r.append(x)\n",
    "\n",
    "    return i, r\n",
    "\n",
    "\n",
    "def dataFromFile(fname):\n",
    "    \"\"\"Function which reads from the file and yields a generator\"\"\"\n",
    "    with open(fname, \"rU\") as file_iter:\n",
    "        for line in file_iter:\n",
    "            line = line.strip().rstrip(\",\")  # Remove trailing comma\n",
    "            record = frozenset(line.split(\",\"))\n",
    "            yield record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------ RULES:\n"
     ]
    }
   ],
   "source": [
    "items, rules = runApriori('testr.csv',0.3,0.2)\n",
    "printResults(items, rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39, ' State-gov', 77516, ..., 40, ' United-States', ' <=50K'],\n",
       "       [50, ' Self-emp-not-inc', 83311, ..., 13, ' United-States',\n",
       "        ' <=50K'],\n",
       "       [38, ' Private', 215646, ..., 40, ' United-States', ' <=50K'],\n",
       "       ...,\n",
       "       [58, ' Private', 151910, ..., 40, ' United-States', ' <=50K'],\n",
       "       [22, ' Private', 201490, ..., 20, ' United-States', ' <=50K'],\n",
       "       [52, ' Self-emp-inc', 287927, ..., 40, ' United-States', ' >50K']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(itemSetList1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#freqItemSet1, rules1 = apriori(np.array(itemSetList1), minSup=0.6, minConf=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed =  1.876664638519287\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "itemSetList2=itemSetList1.iloc[:1000]\n",
    "freqItemSet1, rules1 = apriori(np.array(itemSetList2), minSup=0.6, minConf=0.8)\n",
    "end=time.time()\n",
    "print(\"Time elapsed = \",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freqItemSet1, rules1 = apriori(np.array(itemSetList2), minSup=0.6, minConf=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {frozenset({' Private'}),\n",
       "  frozenset({' White'}),\n",
       "  frozenset({' <=50K'}),\n",
       "  frozenset({' United-States'}),\n",
       "  frozenset({' Male'}),\n",
       "  frozenset({0})},\n",
       " 2: {frozenset({' <=50K', ' United-States'}),\n",
       "  frozenset({' <=50K', 0}),\n",
       "  frozenset({' Private', ' United-States'}),\n",
       "  frozenset({' Private', 0}),\n",
       "  frozenset({' United-States', 0}),\n",
       "  frozenset({' Male', ' United-States'}),\n",
       "  frozenset({' Male', 0}),\n",
       "  frozenset({' <=50K', ' White'}),\n",
       "  frozenset({' United-States', ' White'}),\n",
       "  frozenset({' White', 0})},\n",
       " 3: {frozenset({' <=50K', ' United-States', 0}),\n",
       "  frozenset({' Private', ' United-States', 0}),\n",
       "  frozenset({' Male', ' United-States', 0}),\n",
       "  frozenset({' <=50K', ' White', 0}),\n",
       "  frozenset({' United-States', ' White', 0})}}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqItemSet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-f53486f1e984>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitemSetList2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m' 2174'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "pd.unique(itemSetList2[' 2174'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31    293\n",
       "35    277\n",
       "33    277\n",
       "34    273\n",
       "25    272\n",
       "     ... \n",
       "84      3\n",
       "82      2\n",
       "83      2\n",
       "88      1\n",
       "85      1\n",
       "Name: 39, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemSetList2['39'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-27de38a7df5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mitemSetList2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitemSetList1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfreqItemSet1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrules1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapriori\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitemSetList2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminSup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminConf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Time elapsed = \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-102-0734ccd953ec>\u001b[0m in \u001b[0;36mapriori\u001b[1;34m(itemSetList, minSup, minConf)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mglobalItemSetWithSup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mL1ItemSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetAboveMinSup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC1ItemSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitemSetList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminSup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobalItemSetWithSup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mcurrentLSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL1ItemSet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-93-17b2b2a415f1>\u001b[0m in \u001b[0;36mgetAboveMinSup\u001b[1;34m(itemSet, itemSetList, minSup, globalItemSetWithSup)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitemSet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mitemSet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitemSetList\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitemSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m                 \u001b[0mglobalItemSetWithSup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[0mlocalItemSetWithSup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "itemSetList2=itemSetList1\n",
    "freqItemSet1, rules1 = apriori(np.array(itemSetList2), minSup=0.6, minConf=0.8)\n",
    "end=time.time()\n",
    "print(\"Time elapsed = \",end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {frozenset({' Private'}),\n",
       "  frozenset({' White'}),\n",
       "  frozenset({' <=50K'}),\n",
       "  frozenset({' United-States'}),\n",
       "  frozenset({' Male'}),\n",
       "  frozenset({0})},\n",
       " 2: {frozenset({' <=50K', ' United-States'}),\n",
       "  frozenset({' <=50K', 0}),\n",
       "  frozenset({' Private', ' United-States'}),\n",
       "  frozenset({' Private', 0}),\n",
       "  frozenset({' United-States', 0}),\n",
       "  frozenset({' Male', 0}),\n",
       "  frozenset({' <=50K', ' White'}),\n",
       "  frozenset({' United-States', ' White'}),\n",
       "  frozenset({' White', 0})},\n",
       " 3: {frozenset({' <=50K', ' United-States', 0}),\n",
       "  frozenset({' United-States', ' White', 0}),\n",
       "  frozenset({' <=50K', ' White', 0}),\n",
       "  frozenset({' Private', ' United-States', 0})}}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqItemSet1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{' <=50K'}, {' White'}, 0.8373381877022654],\n",
       " [{' <=50K'}, {' White', 0}, 0.8373381877022654],\n",
       " [{' <=50K', 0}, {' White'}, 0.8373381877022654],\n",
       " [{0}, {' White'}, 0.8542735173981143],\n",
       " [{' United-States'}, {' White'}, 0.8783339046966061],\n",
       " [{' United-States'}, {' White', 0}, 0.8783339046966061],\n",
       " [{' United-States', 0}, {' White'}, 0.8783339046966061],\n",
       " [{' Private'}, {' United-States'}, 0.8871607331688404],\n",
       " [{' Private'}, {' United-States', 0}, 0.8871607331688404],\n",
       " [{' Private', 0}, {' United-States'}, 0.8871607331688404],\n",
       " [{' <=50K'}, {' United-States'}, 0.8899271844660194],\n",
       " [{' <=50K'}, {' United-States', 0}, 0.8899271844660194],\n",
       " [{' <=50K', 0}, {' United-States'}, 0.8899271844660194],\n",
       " [{0}, {' United-States'}, 0.895857006848684],\n",
       " [{' White'}, {' United-States'}, 0.9210885821110153],\n",
       " [{' White'}, {' United-States', 0}, 0.9210885821110153],\n",
       " [{' White', 0}, {' United-States'}, 0.9210885821110153],\n",
       " [{' <=50K'}, {0}, 1.0],\n",
       " [{' Private'}, {0}, 1.0],\n",
       " [{' United-States'}, {0}, 1.0],\n",
       " [{' Male'}, {0}, 1.0],\n",
       " [{' White'}, {0}, 1.0],\n",
       " [{' <=50K', ' United-States'}, {0}, 1.0],\n",
       " [{' United-States', ' White'}, {0}, 1.0],\n",
       " [{' <=50K', ' White'}, {0}, 1.0],\n",
       " [{' Private', ' United-States'}, {0}, 1.0]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpgrowthFromFile(fname, minSupRatio, minConf):\n",
    "    itemSetList, frequency = getFromFile(fname)\n",
    "    minSup = len(itemSetList) * minSupRatio\n",
    "    fpTree, headerTable = constructTree(itemSetList, frequency, minSup)\n",
    "\n",
    "    freqItems = []\n",
    "    mineTree(headerTable, minSup, set(), freqItems)\n",
    "    rules = associationRule(freqItems, itemSetList, minConf)\n",
    "    return freqItems, rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructTree(itemSetList, frequency, minSup):\n",
    "    headerTable = defaultdict(int)\n",
    "    # Counting frequency and create header table\n",
    "    for idx, itemSet in enumerate(itemSetList):\n",
    "        for item in itemSet:\n",
    "            headerTable[item] += frequency[idx]\n",
    "\n",
    "    # Deleting items below minSup\n",
    "    headerTable = dict((item, sup) for item, sup in headerTable.items() if sup >= minSup)\n",
    "    if(len(headerTable) == 0):\n",
    "        return None, None\n",
    "\n",
    "    # HeaderTable column [Item: [frequency, headNode]]\n",
    "    for item in headerTable:\n",
    "        headerTable[item] = [headerTable[item], None]\n",
    "\n",
    "    # Init Null head node\n",
    "    fpTree = Node('Null', 1, None)\n",
    "    # Update FP tree for each cleaned and sorted itemSet\n",
    "    for idx, itemSet in enumerate(itemSetList):\n",
    "        itemSet = [item for item in itemSet if item in headerTable]\n",
    "        itemSet.sort(key=lambda item: headerTable[item][0], reverse=True)\n",
    "        # Traverse from root to leaf, update tree with given item\n",
    "        currentNode = fpTree\n",
    "        for item in itemSet:\n",
    "            currentNode = updateTree(item, currentNode, headerTable, frequency[idx])\n",
    "\n",
    "    return fpTree, headerTable\n",
    "\n",
    "def updateTree(item, treeNode, headerTable, frequency):\n",
    "    if item in treeNode.children:\n",
    "        # If the item already exists, increment the count\n",
    "        treeNode.children[item].increment(frequency)\n",
    "    else:\n",
    "        # Create a new branch\n",
    "        newItemNode = Node(item, frequency, treeNode)\n",
    "        treeNode.children[item] = newItemNode\n",
    "        # Link the new branch to header table\n",
    "        updateHeaderTable(item, newItemNode, headerTable)\n",
    "\n",
    "    return treeNode.children[item]\n",
    "\n",
    "def updateHeaderTable(item, targetNode, headerTable):\n",
    "    if(headerTable[item][1] == None):\n",
    "        headerTable[item][1] = targetNode\n",
    "    else:\n",
    "        currentNode = headerTable[item][1]\n",
    "        # Traverse to the last node then link it to the target\n",
    "        while currentNode.next != None:\n",
    "            currentNode = currentNode.next\n",
    "        currentNode.next = targetNode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mineTree(headerTable, minSup, preFix, freqItemList):\n",
    "    # Sort the items with frequency and create a list\n",
    "    sortedItemList = [item[0] for item in sorted(list(headerTable.items()), key=lambda p:p[1][0])] \n",
    "    # Start with the lowest frequency\n",
    "    for item in sortedItemList:  \n",
    "        # Pattern growth is achieved by the concatenation of suffix pattern with frequent patterns generated from conditional FP-tree\n",
    "        newFreqSet = preFix.copy()\n",
    "        newFreqSet.add(item)\n",
    "        freqItemList.append(newFreqSet)\n",
    "        # Find all prefix path, constrcut conditional pattern base\n",
    "        conditionalPattBase, frequency = findPrefixPath(item, headerTable) \n",
    "        # Construct conditonal FP Tree with conditional pattern base\n",
    "        conditionalTree, newHeaderTable = constructTree(conditionalPattBase, frequency, minSup) \n",
    "        if newHeaderTable != None:\n",
    "            # Mining recursively on the tree\n",
    "            mineTree(newHeaderTable, minSup,\n",
    "                       newFreqSet, freqItemList)\n",
    "\n",
    "def findPrefixPath(basePat, headerTable):\n",
    "    # First node in linked list\n",
    "    treeNode = headerTable[basePat][1] \n",
    "    condPats = []\n",
    "    frequency = []\n",
    "    while treeNode != None:\n",
    "        prefixPath = []\n",
    "        # From leaf node all the way to root\n",
    "        ascendFPtree(treeNode, prefixPath)  \n",
    "        if len(prefixPath) > 1:\n",
    "            # Storing the prefix path and it's corresponding count\n",
    "            condPats.append(prefixPath[1:])\n",
    "            frequency.append(treeNode.count)\n",
    "\n",
    "        # Go to next node\n",
    "        treeNode = treeNode.next  \n",
    "    return condPats, frequency\n",
    "\n",
    "def ascendFPtree(node, prefixPath):\n",
    "    if node.parent != None:\n",
    "        prefixPath.append(node.itemName)\n",
    "        ascendFPtree(node.parent, prefixPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, OrderedDict\n",
    "from csv import reader\n",
    "from itertools import chain, combinations\n",
    "import time\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, itemName, frequency, parentNode):\n",
    "        self.itemName = itemName\n",
    "        self.count = frequency\n",
    "        self.parent = parentNode\n",
    "        self.children = {}\n",
    "        self.next = None\n",
    "\n",
    "    def increment(self, frequency):\n",
    "        self.count += frequency\n",
    "\n",
    "    def display(self, ind=1):\n",
    "        print('  ' * ind, self.itemName, ' ', self.count)\n",
    "        for child in list(self.children.values()):\n",
    "            child.display(ind+1)\n",
    "\n",
    "def getFromFile(fname):\n",
    "    itemSetList = []\n",
    "    frequency = []\n",
    "    \n",
    "    with open(fname, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for line in csv_reader:\n",
    "            line = list(filter(None, line))\n",
    "            itemSetList.append(line)\n",
    "            frequency.append(1)\n",
    "\n",
    "    return itemSetList, frequency\n",
    "\n",
    "def constructTree(itemSetList, frequency, minSup):\n",
    "    headerTable = defaultdict(int)\n",
    "    # Counting frequency and create header table\n",
    "    for idx, itemSet in enumerate(itemSetList):\n",
    "        for item in itemSet:\n",
    "            headerTable[item] += frequency[idx]\n",
    "\n",
    "    # Deleting items below minSup\n",
    "    headerTable = dict((item, sup) for item, sup in headerTable.items() if sup >= minSup)\n",
    "    if(len(headerTable) == 0):\n",
    "        return None, None\n",
    "\n",
    "    # HeaderTable column [Item: [frequency, headNode]]\n",
    "    for item in headerTable:\n",
    "        headerTable[item] = [headerTable[item], None]\n",
    "\n",
    "    # Init Null head node\n",
    "    fpTree = Node('Null', 1, None)\n",
    "    # Update FP tree for each cleaned and sorted itemSet\n",
    "    for idx, itemSet in enumerate(itemSetList):\n",
    "        itemSet = [item for item in itemSet if item in headerTable]\n",
    "        itemSet.sort(key=lambda item: headerTable[item][0], reverse=False)\n",
    "        # Traverse from root to leaf, update tree with given item\n",
    "        currentNode = fpTree\n",
    "        for item in itemSet:\n",
    "            currentNode = updateTree(item, currentNode, headerTable, frequency[idx])\n",
    "\n",
    "    return fpTree, headerTable\n",
    "\n",
    "def updateHeaderTable(item, targetNode, headerTable):\n",
    "    if(headerTable[item][1] == None):\n",
    "        headerTable[item][1] = targetNode\n",
    "    else:\n",
    "        currentNode = headerTable[item][1]\n",
    "        # Traverse to the last node then link it to the target\n",
    "        while currentNode.next != None:\n",
    "            currentNode = currentNode.next\n",
    "        currentNode.next = targetNode\n",
    "\n",
    "def updateTree(item, treeNode, headerTable, frequency):\n",
    "    if item in treeNode.children:\n",
    "        # If the item already exists, increment the count\n",
    "        treeNode.children[item].increment(frequency)\n",
    "    else:\n",
    "        # Create a new branch\n",
    "        newItemNode = Node(item, frequency, treeNode)\n",
    "        treeNode.children[item] = newItemNode\n",
    "        # Link the new branch to header table\n",
    "        updateHeaderTable(item, newItemNode, headerTable)\n",
    "\n",
    "    return treeNode.children[item]\n",
    "\n",
    "def ascendFPtree(node, prefixPath):\n",
    "    if node.parent != None:\n",
    "        prefixPath.append(node.itemName)\n",
    "        ascendFPtree(node.parent, prefixPath)\n",
    "\n",
    "def findPrefixPath(basePat, headerTable):\n",
    "    # First node in linked list\n",
    "    treeNode = headerTable[basePat][1] \n",
    "    condPats = []\n",
    "    frequency = []\n",
    "    while treeNode != None:\n",
    "        prefixPath = []\n",
    "        # From leaf node all the way to root\n",
    "        ascendFPtree(treeNode, prefixPath)  \n",
    "        if len(prefixPath) > 1:\n",
    "            # Storing the prefix path and it's corresponding count\n",
    "            condPats.append(prefixPath[1:])\n",
    "            frequency.append(treeNode.count)\n",
    "\n",
    "        # Go to next node\n",
    "        treeNode = treeNode.next  \n",
    "    return condPats, frequency\n",
    "\n",
    "def mineTree(headerTable, minSup, preFix, freqItemList):\n",
    "    # Sort the items with frequency and create a list\n",
    "    sortedItemList = [item[0] for item in sorted(list(headerTable.items()), key=lambda p:p[1][0])] \n",
    "    print('Finish sorting:', sortedItemList)\n",
    "    # Start with the lowest frequency\n",
    "    for item in sortedItemList:  \n",
    "        print('Checking item:', item)\n",
    "        print('in', sortedItemList)\n",
    "        # Pattern growth is achieved by the concatenation of suffix pattern with frequent patterns generated from conditional FP-tree\n",
    "        newFreqSet = preFix.copy()\n",
    "        newFreqSet.add(item)\n",
    "        print('Adding new frequent set: ', newFreqSet)\n",
    "        freqItemList.append(newFreqSet)\n",
    "        # Find all prefix path, constrcut conditional pattern base\n",
    "        conditionalPattBase, frequency = findPrefixPath(item, headerTable) \n",
    "        # Construct conditonal FP Tree with conditional pattern base\n",
    "        conditionalTree, newHeaderTable = constructTree(conditionalPattBase, frequency, minSup) \n",
    "        print(newHeaderTable)\n",
    "        if newHeaderTable != None:\n",
    "            print('Conditional tree for item:', item)\n",
    "            conditionalTree.display()\n",
    "            print()\n",
    "            # print('current item', item)\n",
    "            # print('conditional tree for: ', newFreqSet)\n",
    "            # conditionalTree.display(1)\n",
    "\n",
    "            # Mining recursively on the tree\n",
    "            mineTree(newHeaderTable, minSup,\n",
    "                       newFreqSet, freqItemList)\n",
    "        else:\n",
    "            print()\n",
    "\n",
    "def powerset(s):\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1, len(s)))\n",
    "\n",
    "def getSupport(testSet, itemSetList):\n",
    "    count = 0\n",
    "    for itemSet in itemSetList:\n",
    "        if(set(testSet).issubset(itemSet)):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def associationRule(freqItemSet, itemSetList, minConf):\n",
    "    rules = []\n",
    "    for itemSet in freqItemSet:\n",
    "        subsets = powerset(itemSet)\n",
    "        for s in subsets:\n",
    "            confidence = float(getSupport(itemSet, itemSetList) / getSupport(s, itemSetList))\n",
    "            if(confidence > minConf):\n",
    "                rules.append([set(s), set(itemSet.difference(s)),\n",
    "                              confidence, getSupport(itemSet, itemSetList), getSupport(s, itemSetList)])\n",
    "    return rules\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish sorting: [' Male', ' Private', ' <=50K', ' White', ' United-States', ' 0']\n",
      "Checking item:  Male\n",
      "in [' Male', ' Private', ' <=50K', ' White', ' United-States', ' 0']\n",
      "Adding new frequent set:  {' Male'}\n",
      "None\n",
      "\n",
      "Checking item:  Private\n",
      "in [' Male', ' Private', ' <=50K', ' White', ' United-States', ' 0']\n",
      "Adding new frequent set:  {' Private'}\n",
      "None\n",
      "\n",
      "Checking item:  <=50K\n",
      "in [' Male', ' Private', ' <=50K', ' White', ' United-States', ' 0']\n",
      "Adding new frequent set:  {' <=50K'}\n",
      "None\n",
      "\n",
      "Checking item:  White\n",
      "in [' Male', ' Private', ' <=50K', ' White', ' United-States', ' 0']\n",
      "Adding new frequent set:  {' White'}\n",
      "{' <=50K': [20699, <__main__.Node object at 0x0000025193D4BBC8>]}\n",
      "Conditional tree for item:  White\n",
      "   Null   1\n",
      "      <=50K   20699\n",
      "\n",
      "Finish sorting: [' <=50K']\n",
      "Checking item:  <=50K\n",
      "in [' <=50K']\n",
      "Adding new frequent set:  {' <=50K', ' White'}\n",
      "None\n",
      "\n",
      "Checking item:  United-States\n",
      "in [' Male', ' Private', ' <=50K', ' White', ' United-States', ' 0']\n",
      "Adding new frequent set:  {' United-States'}\n",
      "{' White': [25621, <__main__.Node object at 0x0000025193D4BE88>], ' <=50K': [21999, <__main__.Node object at 0x0000025193D4BD48>], ' Private': [20135, <__main__.Node object at 0x0000025193D4BEC8>]}\n",
      "Conditional tree for item:  United-States\n",
      "   Null   1\n",
      "      <=50K   6405\n",
      "        White   5465\n",
      "      Private   20135\n",
      "        <=50K   15594\n",
      "          White   13452\n",
      "        White   4276\n",
      "      White   2428\n",
      "\n",
      "Finish sorting: [' Private', ' <=50K', ' White']\n",
      "Checking item:  Private\n",
      "in [' Private', ' <=50K', ' White']\n",
      "Adding new frequent set:  {' Private', ' United-States'}\n",
      "None\n",
      "\n",
      "Checking item:  <=50K\n",
      "in [' Private', ' <=50K', ' White']\n",
      "Adding new frequent set:  {' <=50K', ' United-States'}\n",
      "None\n",
      "\n",
      "Checking item:  White\n",
      "in [' Private', ' <=50K', ' White']\n",
      "Adding new frequent set:  {' White', ' United-States'}\n",
      "None\n",
      "\n",
      "Checking item:  0\n",
      "in [' Male', ' Private', ' <=50K', ' White', ' United-States', ' 0']\n",
      "Adding new frequent set:  {' 0'}\n",
      "{' United-States': [54490, <__main__.Node object at 0x0000025193D50408>], ' White': [51877, <__main__.Node object at 0x0000025193D503C8>], ' <=50K': [47659, <__main__.Node object at 0x0000025193D50388>], ' Male': [40341, <__main__.Node object at 0x0000025193D50348>], ' 0': [28330, <__main__.Node object at 0x0000025193D50488>], ' Private': [42678, <__main__.Node object at 0x0000025193D505C8>]}\n",
      "Conditional tree for item:  0\n",
      "   Null   1\n",
      "      Male   21790\n",
      "        <=50K   4421\n",
      "          White   3855\n",
      "            United-States   3632\n",
      "          United-States   427\n",
      "        Private   14944\n",
      "          <=50K   10707\n",
      "            White   9230\n",
      "              United-States   8281\n",
      "            United-States   1049\n",
      "          White   3893\n",
      "            United-States   3675\n",
      "          United-States   204\n",
      "        White   2196\n",
      "          United-States   2065\n",
      "        United-States   155\n",
      "      0   28330\n",
      "        Male   18551\n",
      "          <=50K   4047\n",
      "            White   3529\n",
      "              United-States   3328\n",
      "            United-States   394\n",
      "          Private   12869\n",
      "            <=50K   9916\n",
      "              White   8521\n",
      "                United-States   7624\n",
      "              United-States   995\n",
      "            United-States   132\n",
      "            White   2727\n",
      "              United-States   2569\n",
      "          White   1477\n",
      "            United-States   1388\n",
      "          United-States   116\n",
      "        Private   7113\n",
      "          <=50K   6613\n",
      "            White   5300\n",
      "              United-States   4860\n",
      "            United-States   1035\n",
      "          White   440\n",
      "            United-States   406\n",
      "          United-States   39\n",
      "        White   256\n",
      "          United-States   241\n",
      "        <=50K   2363\n",
      "          White   1811\n",
      "            United-States   1681\n",
      "          United-States   477\n",
      "        United-States   35\n",
      "      Private   7752\n",
      "        <=50K   7026\n",
      "          White   5642\n",
      "            United-States   5171\n",
      "          United-States   1093\n",
      "        White   639\n",
      "          United-States   601\n",
      "        United-States   61\n",
      "      White   389\n",
      "        United-States   363\n",
      "      <=50K   2566\n",
      "        White   1972\n",
      "          United-States   1833\n",
      "        United-States   513\n",
      "      United-States   47\n",
      "\n",
      "Finish sorting: [' 0', ' Male', ' Private', ' <=50K', ' White', ' United-States']\n",
      "Checking item:  0\n",
      "in [' 0', ' Male', ' Private', ' <=50K', ' White', ' United-States']\n",
      "Adding new frequent set:  {' 0'}\n",
      "None\n",
      "\n",
      "Checking item:  Male\n",
      "in [' 0', ' Male', ' Private', ' <=50K', ' White', ' United-States']\n",
      "Adding new frequent set:  {' 0', ' Male'}\n",
      "None\n",
      "\n",
      "Checking item:  Private\n",
      "in [' 0', ' Male', ' Private', ' <=50K', ' White', ' United-States']\n",
      "Adding new frequent set:  {' Private', ' 0'}\n",
      "{' Male': [27813, <__main__.Node object at 0x0000025193D56348>], ' 0': [19982, <__main__.Node object at 0x0000025193D56388>]}\n",
      "Conditional tree for item:  Private\n",
      "   Null   1\n",
      "      Male   14944\n",
      "      0   19982\n",
      "        Male   12869\n",
      "\n",
      "Finish sorting: [' 0', ' Male']\n",
      "Checking item:  0\n",
      "in [' 0', ' Male']\n",
      "Adding new frequent set:  {' Private', ' 0'}\n",
      "None\n",
      "\n",
      "Checking item:  Male\n",
      "in [' 0', ' Male']\n",
      "Adding new frequent set:  {' Private', ' 0', ' Male'}\n",
      "None\n",
      "\n",
      "Checking item:  <=50K\n",
      "in [' 0', ' Male', ' Private', ' <=50K', ' White', ' United-States']\n",
      "Adding new frequent set:  {' 0', ' <=50K'}\n",
      "{' Male': [29091, <__main__.Node object at 0x0000025193D56848>], ' 0': [22939, <__main__.Node object at 0x0000025193D56888>], ' Private': [34262, <__main__.Node object at 0x0000025193D56908>]}\n",
      "Conditional tree for item:  <=50K\n",
      "   Null   1\n",
      "      Male   15128\n",
      "        Private   10707\n",
      "      0   22939\n",
      "        Male   13963\n",
      "          Private   9916\n",
      "        Private   6613\n",
      "      Private   7026\n",
      "\n",
      "Finish sorting: [' 0', ' Male', ' Private']\n",
      "Checking item:  0\n",
      "in [' 0', ' Male', ' Private']\n",
      "Adding new frequent set:  {' 0', ' <=50K'}\n",
      "None\n",
      "\n",
      "Checking item:  Male\n",
      "in [' 0', ' Male', ' Private']\n",
      "Adding new frequent set:  {' 0', ' Male', ' <=50K'}\n",
      "None\n",
      "\n",
      "Checking item:  Private\n",
      "in [' 0', ' Male', ' Private']\n",
      "Adding new frequent set:  {' Private', ' 0', ' <=50K'}\n",
      "{' Male': [20623, <__main__.Node object at 0x0000025193D590C8>]}\n",
      "Conditional tree for item:  Private\n",
      "   Null   1\n",
      "      Male   20623\n",
      "\n",
      "Finish sorting: [' Male']\n",
      "Checking item:  Male\n",
      "in [' Male']\n",
      "Adding new frequent set:  {' Private', ' 0', ' Male', ' <=50K'}\n",
      "None\n",
      "\n",
      "Checking item:  White\n",
      "in [' 0', ' Male', ' Private', ' <=50K', ' White', ' United-States']\n",
      "Adding new frequent set:  {' 0', ' White'}\n",
      "{' <=50K': [39860, <__main__.Node object at 0x0000025193D56FC8>], ' Male': [35428, <__main__.Node object at 0x0000025193D56E48>], ' 0': [24061, <__main__.Node object at 0x0000025193D59248>], ' Private': [36392, <__main__.Node object at 0x0000025193D59388>]}\n",
      "Conditional tree for item:  White\n",
      "   Null   1\n",
      "      Male   19174\n",
      "        <=50K   3855\n",
      "        Private   13123\n",
      "          <=50K   9230\n",
      "      0   24061\n",
      "        Male   16254\n",
      "          <=50K   3529\n",
      "          Private   11248\n",
      "            <=50K   8521\n",
      "        Private   5740\n",
      "          <=50K   5300\n",
      "        <=50K   1811\n",
      "      Private   6281\n",
      "        <=50K   5642\n",
      "      <=50K   1972\n",
      "\n",
      "Finish sorting: [' 0', ' Male', ' Private', ' <=50K']\n",
      "Checking item:  0\n",
      "in [' 0', ' Male', ' Private', ' <=50K']\n",
      "Adding new frequent set:  {' 0', ' White'}\n",
      "None\n",
      "\n",
      "Checking item:  Male\n",
      "in [' 0', ' Male', ' Private', ' <=50K']\n",
      "Adding new frequent set:  {' 0', ' White', ' Male'}\n",
      "None\n",
      "\n",
      "Checking item:  Private\n",
      "in [' 0', ' Male', ' Private', ' <=50K']\n",
      "Adding new frequent set:  {' Private', ' 0', ' White'}\n",
      "{' Male': [24371, <__main__.Node object at 0x0000025193D5D188>]}\n",
      "Conditional tree for item:  Private\n",
      "   Null   1\n",
      "      Male   24371\n",
      "\n",
      "Finish sorting: [' Male']\n",
      "Checking item:  Male\n",
      "in [' Male']\n",
      "Adding new frequent set:  {' Private', ' 0', ' White', ' Male'}\n",
      "None\n",
      "\n",
      "Checking item:  <=50K\n",
      "in [' 0', ' Male', ' Private', ' <=50K']\n",
      "Adding new frequent set:  {' 0', ' White', ' <=50K'}\n",
      "{' Male': [25135, <__main__.Node object at 0x0000025193D5D4C8>], ' Private': [28693, <__main__.Node object at 0x0000025193D5D508>]}\n",
      "Conditional tree for item:  <=50K\n",
      "   Null   1\n",
      "      Male   25135\n",
      "        Private   17751\n",
      "      Private   10942\n",
      "\n",
      "Finish sorting: [' Male', ' Private']\n",
      "Checking item:  Male\n",
      "in [' Male', ' Private']\n",
      "Adding new frequent set:  {' 0', ' White', ' Male', ' <=50K'}\n",
      "None\n",
      "\n",
      "Checking item:  Private\n",
      "in [' Male', ' Private']\n",
      "Adding new frequent set:  {' Private', ' 0', ' White', ' <=50K'}\n",
      "None\n",
      "\n",
      "Checking item:  United-States\n",
      "in [' 0', ' Male', ' Private', ' <=50K', ' White', ' United-States']\n",
      "Adding new frequent set:  {' 0', ' United-States'}\n",
      "{' White': [47718, <__main__.Node object at 0x0000025193D598C8>], ' <=50K': [42393, <__main__.Node object at 0x0000025193D59A08>], ' Male': [36034, <__main__.Node object at 0x0000025193D59DC8>], ' 0': [25320, <__main__.Node object at 0x0000025193D59C08>], ' Private': [37795, <__main__.Node object at 0x0000025193D5D3C8>]}\n",
      "Conditional tree for item:  United-States\n",
      "   Null   1\n",
      "      Male   19488\n",
      "        <=50K   4059\n",
      "          White   3632\n",
      "        Private   13209\n",
      "          <=50K   9330\n",
      "            White   8281\n",
      "          White   3675\n",
      "        White   2065\n",
      "      0   25320\n",
      "        Male   16546\n",
      "          <=50K   3722\n",
      "            White   3328\n",
      "          Private   11320\n",
      "            <=50K   8619\n",
      "              White   7624\n",
      "            White   2569\n",
      "          White   1388\n",
      "        Private   6340\n",
      "          <=50K   5895\n",
      "            White   4860\n",
      "          White   406\n",
      "        White   241\n",
      "        <=50K   2158\n",
      "          White   1681\n",
      "      Private   6926\n",
      "        <=50K   6264\n",
      "          White   5171\n",
      "        White   601\n",
      "      White   363\n",
      "      <=50K   2346\n",
      "        White   1833\n",
      "\n",
      "Finish sorting: [' 0', ' Male', ' Private', ' <=50K', ' White']\n",
      "Checking item:  0\n",
      "in [' 0', ' Male', ' Private', ' <=50K', ' White']\n",
      "Adding new frequent set:  {' 0', ' United-States'}\n",
      "None\n",
      "\n",
      "Checking item:  Male\n",
      "in [' 0', ' Male', ' Private', ' <=50K', ' White']\n",
      "Adding new frequent set:  {' 0', ' Male', ' United-States'}\n",
      "None\n",
      "\n",
      "Checking item:  Private\n",
      "in [' 0', ' Male', ' Private', ' <=50K', ' White']\n",
      "Adding new frequent set:  {' Private', ' 0', ' United-States'}\n",
      "{' Male': [24529, <__main__.Node object at 0x0000025193D60348>]}\n",
      "Conditional tree for item:  Private\n",
      "   Null   1\n",
      "      Male   24529\n",
      "\n",
      "Finish sorting: [' Male']\n",
      "Checking item:  Male\n",
      "in [' Male']\n",
      "Adding new frequent set:  {' Private', ' 0', ' Male', ' United-States'}\n",
      "None\n",
      "\n",
      "Checking item:  <=50K\n",
      "in [' 0', ' Male', ' Private', ' <=50K', ' White']\n",
      "Adding new frequent set:  {' 0', ' United-States', ' <=50K'}\n",
      "{' Male': [25730, <__main__.Node object at 0x0000025193D606C8>], ' 0': [20394, <__main__.Node object at 0x0000025193D60708>], ' Private': [30108, <__main__.Node object at 0x0000025193D60788>]}\n",
      "Conditional tree for item:  <=50K\n",
      "   Null   1\n",
      "      Male   13389\n",
      "        Private   9330\n",
      "      0   20394\n",
      "        Male   12341\n",
      "          Private   8619\n",
      "        Private   5895\n",
      "      Private   6264\n",
      "\n",
      "Finish sorting: [' 0', ' Male', ' Private']\n",
      "Checking item:  0\n",
      "in [' 0', ' Male', ' Private']\n",
      "Adding new frequent set:  {' 0', ' United-States', ' <=50K'}\n",
      "None\n",
      "\n",
      "Checking item:  Male\n",
      "in [' 0', ' Male', ' Private']\n",
      "Adding new frequent set:  {' 0', ' Male', ' United-States', ' <=50K'}\n",
      "None\n",
      "\n",
      "Checking item:  Private\n",
      "in [' 0', ' Male', ' Private']\n",
      "Adding new frequent set:  {' Private', ' 0', ' United-States', ' <=50K'}\n",
      "None\n",
      "\n",
      "Checking item:  White\n",
      "in [' 0', ' Male', ' Private', ' <=50K', ' White']\n",
      "Adding new frequent set:  {' 0', ' White', ' United-States'}\n",
      "{' <=50K': [36410, <__main__.Node object at 0x0000025193D60F48>], ' Male': [32562, <__main__.Node object at 0x0000025193D60F08>], ' 0': [22097, <__main__.Node object at 0x0000025193D60F88>], ' Private': [33187, <__main__.Node object at 0x0000025193D63088>]}\n",
      "Conditional tree for item:  White\n",
      "   Null   1\n",
      "      Male   17653\n",
      "        <=50K   3632\n",
      "        Private   11956\n",
      "          <=50K   8281\n",
      "      0   22097\n",
      "        Male   14909\n",
      "          <=50K   3328\n",
      "          Private   10193\n",
      "            <=50K   7624\n",
      "        Private   5266\n",
      "          <=50K   4860\n",
      "        <=50K   1681\n",
      "      Private   5772\n",
      "        <=50K   5171\n",
      "      <=50K   1833\n",
      "\n",
      "Finish sorting: [' 0', ' Male', ' Private', ' <=50K']\n",
      "Checking item:  0\n",
      "in [' 0', ' Male', ' Private', ' <=50K']\n",
      "Adding new frequent set:  {' 0', ' White', ' United-States'}\n",
      "None\n",
      "\n",
      "Checking item:  Male\n",
      "in [' 0', ' Male', ' Private', ' <=50K']\n",
      "Adding new frequent set:  {' 0', ' White', ' Male', ' United-States'}\n",
      "None\n",
      "\n",
      "Checking item:  Private\n",
      "in [' 0', ' Male', ' Private', ' <=50K']\n",
      "Adding new frequent set:  {' Private', ' 0', ' White', ' United-States'}\n",
      "{' Male': [22149, <__main__.Node object at 0x0000025193D63EC8>]}\n",
      "Conditional tree for item:  Private\n",
      "   Null   1\n",
      "      Male   22149\n",
      "\n",
      "Finish sorting: [' Male']\n",
      "Checking item:  Male\n",
      "in [' Male']\n",
      "Adding new frequent set:  {' 0', ' White', ' Male', ' Private', ' United-States'}\n",
      "None\n",
      "\n",
      "Checking item:  <=50K\n",
      "in [' 0', ' Male', ' Private', ' <=50K']\n",
      "Adding new frequent set:  {' 0', ' White', ' United-States', ' <=50K'}\n",
      "{' Male': [22865, <__main__.Node object at 0x0000025193D66248>], ' Private': [25936, <__main__.Node object at 0x0000025193D66288>]}\n",
      "Conditional tree for item:  <=50K\n",
      "   Null   1\n",
      "      Male   22865\n",
      "        Private   15905\n",
      "      Private   10031\n",
      "\n",
      "Finish sorting: [' Male', ' Private']\n",
      "Checking item:  Male\n",
      "in [' Male', ' Private']\n",
      "Adding new frequent set:  {' 0', ' White', ' Male', ' <=50K', ' United-States'}\n",
      "None\n",
      "\n",
      "Checking item:  Private\n",
      "in [' Male', ' Private']\n",
      "Adding new frequent set:  {' 0', ' White', ' Private', ' <=50K', ' United-States'}\n",
      "None\n",
      "\n",
      "0.32189011573791504\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    minSupRatio = 0.6\n",
    "    minConf = 0.8\n",
    "    fname = 'testr'\n",
    "    itemSetList, frequency = getFromFile(fname + '.csv')\n",
    "    minSup = len(itemSetList) * minSupRatio\n",
    "    startTime = time.time()\n",
    "    fpTree, headerTable = constructTree(itemSetList, frequency, minSup)\n",
    "    # fpTree.display()\n",
    "    if(fpTree == None):\n",
    "        print('No frequent item set')\n",
    "    else:\n",
    "        # fpTree.display()\n",
    "        freqItems = []\n",
    "        mineTree(headerTable, minSup, set(), freqItems)\n",
    "        print(time.time() - startTime)\n",
    "        # print('Frequent patterns:')\n",
    "        # for x in freqItems:\n",
    "        #     print(x)\n",
    "\n",
    "        # rules = associationRule(freqItems, itemSetList, minConf)\n",
    "        # print('\\nRules:')\n",
    "        # for rule in rules:\n",
    "        #     print('{} ==> {}   {:.3f}   sup: {:.3f}  subsetsup: {:.3f}'.format(rule[0], rule[1], rule[2], rule[3] / len(itemSetList), rule[4] / len(itemSetList)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent patterns:\n",
      "{' Male'}\n",
      "{' Private'}\n",
      "{' <=50K'}\n",
      "{' White'}\n",
      "{' <=50K', ' White'}\n",
      "{' United-States'}\n",
      "{' Private', ' United-States'}\n",
      "{' <=50K', ' United-States'}\n",
      "{' White', ' United-States'}\n",
      "{' 0'}\n",
      "{' 0'}\n",
      "{' 0', ' Male'}\n",
      "{' Private', ' 0'}\n",
      "{' Private', ' 0'}\n",
      "{' Private', ' 0', ' Male'}\n",
      "{' 0', ' <=50K'}\n",
      "{' 0', ' <=50K'}\n",
      "{' 0', ' Male', ' <=50K'}\n",
      "{' Private', ' 0', ' <=50K'}\n",
      "{' Private', ' 0', ' Male', ' <=50K'}\n",
      "{' 0', ' White'}\n",
      "{' 0', ' White'}\n",
      "{' 0', ' White', ' Male'}\n",
      "{' Private', ' 0', ' White'}\n",
      "{' Private', ' 0', ' White', ' Male'}\n",
      "{' 0', ' White', ' <=50K'}\n",
      "{' 0', ' White', ' Male', ' <=50K'}\n",
      "{' Private', ' 0', ' White', ' <=50K'}\n",
      "{' 0', ' United-States'}\n",
      "{' 0', ' United-States'}\n",
      "{' 0', ' Male', ' United-States'}\n",
      "{' Private', ' 0', ' United-States'}\n",
      "{' Private', ' 0', ' Male', ' United-States'}\n",
      "{' 0', ' United-States', ' <=50K'}\n",
      "{' 0', ' United-States', ' <=50K'}\n",
      "{' 0', ' Male', ' United-States', ' <=50K'}\n",
      "{' Private', ' 0', ' United-States', ' <=50K'}\n",
      "{' 0', ' White', ' United-States'}\n",
      "{' 0', ' White', ' United-States'}\n",
      "{' 0', ' White', ' Male', ' United-States'}\n",
      "{' Private', ' 0', ' White', ' United-States'}\n",
      "{' 0', ' White', ' Male', ' Private', ' United-States'}\n",
      "{' 0', ' White', ' United-States', ' <=50K'}\n",
      "{' 0', ' White', ' Male', ' <=50K', ' United-States'}\n",
      "{' 0', ' White', ' Private', ' <=50K', ' United-States'}\n"
     ]
    }
   ],
   "source": [
    "print('Frequent patterns:')\n",
    "for x in freqItems:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freqItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rules:\n",
      "{' <=50K'} ==> {' White'}   0.837   sup: 0.636  subsetsup: 0.759\n",
      "{' Private'} ==> {' United-States'}   0.887   sup: 0.618  subsetsup: 0.697\n",
      "{' <=50K'} ==> {' United-States'}   0.890   sup: 0.676  subsetsup: 0.759\n",
      "{' White'} ==> {' United-States'}   0.921   sup: 0.787  subsetsup: 0.854\n",
      "{' United-States'} ==> {' White'}   0.878   sup: 0.787  subsetsup: 0.896\n",
      "{' Male'} ==> {' 0'}   1.000   sup: 0.669  subsetsup: 0.669\n",
      "{' Private'} ==> {' 0'}   1.000   sup: 0.697  subsetsup: 0.697\n",
      "{' Private'} ==> {' 0'}   1.000   sup: 0.697  subsetsup: 0.697\n",
      "{' Private', ' Male'} ==> {' 0'}   1.000   sup: 0.459  subsetsup: 0.459\n",
      "{' <=50K'} ==> {' 0'}   1.000   sup: 0.759  subsetsup: 0.759\n",
      "{' <=50K'} ==> {' 0'}   1.000   sup: 0.759  subsetsup: 0.759\n",
      "{' <=50K', ' Male'} ==> {' 0'}   1.000   sup: 0.465  subsetsup: 0.465\n",
      "{' Private', ' <=50K'} ==> {' 0'}   1.000   sup: 0.545  subsetsup: 0.545\n",
      "{' Private', ' <=50K', ' Male'} ==> {' 0'}   1.000   sup: 0.329  subsetsup: 0.329\n",
      "{' 0'} ==> {' White'}   0.854   sup: 0.854  subsetsup: 1.000\n",
      "{' White'} ==> {' 0'}   1.000   sup: 0.854  subsetsup: 0.854\n",
      "{' 0'} ==> {' White'}   0.854   sup: 0.854  subsetsup: 1.000\n",
      "{' White'} ==> {' 0'}   1.000   sup: 0.854  subsetsup: 0.854\n",
      "{' Male'} ==> {' 0', ' White'}   0.880   sup: 0.589  subsetsup: 0.669\n",
      "{' 0', ' Male'} ==> {' White'}   0.880   sup: 0.589  subsetsup: 0.669\n",
      "{' White', ' Male'} ==> {' 0'}   1.000   sup: 0.589  subsetsup: 0.589\n",
      "{' Private'} ==> {' 0', ' White'}   0.855   sup: 0.596  subsetsup: 0.697\n",
      "{' Private', ' 0'} ==> {' White'}   0.855   sup: 0.596  subsetsup: 0.697\n",
      "{' Private', ' White'} ==> {' 0'}   1.000   sup: 0.596  subsetsup: 0.596\n",
      "{' Private', ' Male'} ==> {' 0', ' White'}   0.878   sup: 0.403  subsetsup: 0.459\n",
      "{' Private', ' 0', ' Male'} ==> {' White'}   0.878   sup: 0.403  subsetsup: 0.459\n",
      "{' Private', ' White', ' Male'} ==> {' 0'}   1.000   sup: 0.403  subsetsup: 0.403\n",
      "{' <=50K'} ==> {' 0', ' White'}   0.837   sup: 0.636  subsetsup: 0.759\n",
      "{' 0', ' <=50K'} ==> {' White'}   0.837   sup: 0.636  subsetsup: 0.759\n",
      "{' <=50K', ' White'} ==> {' 0'}   1.000   sup: 0.636  subsetsup: 0.636\n",
      "{' <=50K', ' Male'} ==> {' 0', ' White'}   0.865   sup: 0.402  subsetsup: 0.465\n",
      "{' 0', ' Male', ' <=50K'} ==> {' White'}   0.865   sup: 0.402  subsetsup: 0.465\n",
      "{' <=50K', ' White', ' Male'} ==> {' 0'}   1.000   sup: 0.402  subsetsup: 0.402\n",
      "{' Private', ' <=50K'} ==> {' 0', ' White'}   0.839   sup: 0.457  subsetsup: 0.545\n",
      "{' Private', ' 0', ' <=50K'} ==> {' White'}   0.839   sup: 0.457  subsetsup: 0.545\n",
      "{' Private', ' <=50K', ' White'} ==> {' 0'}   1.000   sup: 0.457  subsetsup: 0.457\n",
      "{' 0'} ==> {' United-States'}   0.896   sup: 0.896  subsetsup: 1.000\n",
      "{' United-States'} ==> {' 0'}   1.000   sup: 0.896  subsetsup: 0.896\n",
      "{' 0'} ==> {' United-States'}   0.896   sup: 0.896  subsetsup: 1.000\n",
      "{' United-States'} ==> {' 0'}   1.000   sup: 0.896  subsetsup: 0.896\n",
      "{' Male'} ==> {' 0', ' United-States'}   0.894   sup: 0.598  subsetsup: 0.669\n",
      "{' 0', ' Male'} ==> {' United-States'}   0.894   sup: 0.598  subsetsup: 0.669\n",
      "{' Male', ' United-States'} ==> {' 0'}   1.000   sup: 0.598  subsetsup: 0.598\n",
      "{' Private'} ==> {' 0', ' United-States'}   0.887   sup: 0.618  subsetsup: 0.697\n",
      "{' Private', ' 0'} ==> {' United-States'}   0.887   sup: 0.618  subsetsup: 0.697\n",
      "{' Private', ' United-States'} ==> {' 0'}   1.000   sup: 0.618  subsetsup: 0.618\n",
      "{' Private', ' Male'} ==> {' 0', ' United-States'}   0.884   sup: 0.406  subsetsup: 0.459\n",
      "{' Private', ' 0', ' Male'} ==> {' United-States'}   0.884   sup: 0.406  subsetsup: 0.459\n",
      "{' Private', ' Male', ' United-States'} ==> {' 0'}   1.000   sup: 0.406  subsetsup: 0.406\n",
      "{' <=50K'} ==> {' 0', ' United-States'}   0.890   sup: 0.676  subsetsup: 0.759\n",
      "{' 0', ' <=50K'} ==> {' United-States'}   0.890   sup: 0.676  subsetsup: 0.759\n",
      "{' <=50K', ' United-States'} ==> {' 0'}   1.000   sup: 0.676  subsetsup: 0.676\n",
      "{' <=50K'} ==> {' 0', ' United-States'}   0.890   sup: 0.676  subsetsup: 0.759\n",
      "{' 0', ' <=50K'} ==> {' United-States'}   0.890   sup: 0.676  subsetsup: 0.759\n",
      "{' <=50K', ' United-States'} ==> {' 0'}   1.000   sup: 0.676  subsetsup: 0.676\n",
      "{' <=50K', ' Male'} ==> {' 0', ' United-States'}   0.885   sup: 0.411  subsetsup: 0.465\n",
      "{' 0', ' Male', ' <=50K'} ==> {' United-States'}   0.885   sup: 0.411  subsetsup: 0.465\n",
      "{' <=50K', ' Male', ' United-States'} ==> {' 0'}   1.000   sup: 0.411  subsetsup: 0.411\n",
      "{' Private', ' <=50K'} ==> {' 0', ' United-States'}   0.879   sup: 0.479  subsetsup: 0.545\n",
      "{' Private', ' 0', ' <=50K'} ==> {' United-States'}   0.879   sup: 0.479  subsetsup: 0.545\n",
      "{' Private', ' <=50K', ' United-States'} ==> {' 0'}   1.000   sup: 0.479  subsetsup: 0.479\n",
      "{' White'} ==> {' 0', ' United-States'}   0.921   sup: 0.787  subsetsup: 0.854\n",
      "{' United-States'} ==> {' 0', ' White'}   0.878   sup: 0.787  subsetsup: 0.896\n",
      "{' 0', ' White'} ==> {' United-States'}   0.921   sup: 0.787  subsetsup: 0.854\n",
      "{' 0', ' United-States'} ==> {' White'}   0.878   sup: 0.787  subsetsup: 0.896\n",
      "{' White', ' United-States'} ==> {' 0'}   1.000   sup: 0.787  subsetsup: 0.787\n",
      "{' White'} ==> {' 0', ' United-States'}   0.921   sup: 0.787  subsetsup: 0.854\n",
      "{' United-States'} ==> {' 0', ' White'}   0.878   sup: 0.787  subsetsup: 0.896\n",
      "{' 0', ' White'} ==> {' United-States'}   0.921   sup: 0.787  subsetsup: 0.854\n",
      "{' 0', ' United-States'} ==> {' White'}   0.878   sup: 0.787  subsetsup: 0.896\n",
      "{' White', ' United-States'} ==> {' 0'}   1.000   sup: 0.787  subsetsup: 0.787\n",
      "{' Male'} ==> {' 0', ' White', ' United-States'}   0.810   sup: 0.542  subsetsup: 0.669\n",
      "{' 0', ' Male'} ==> {' White', ' United-States'}   0.810   sup: 0.542  subsetsup: 0.669\n",
      "{' White', ' Male'} ==> {' 0', ' United-States'}   0.921   sup: 0.542  subsetsup: 0.589\n",
      "{' Male', ' United-States'} ==> {' 0', ' White'}   0.906   sup: 0.542  subsetsup: 0.598\n",
      "{' 0', ' White', ' Male'} ==> {' United-States'}   0.921   sup: 0.542  subsetsup: 0.589\n",
      "{' 0', ' Male', ' United-States'} ==> {' White'}   0.906   sup: 0.542  subsetsup: 0.598\n",
      "{' White', ' Male', ' United-States'} ==> {' 0'}   1.000   sup: 0.542  subsetsup: 0.542\n",
      "{' Private', ' White'} ==> {' 0', ' United-States'}   0.914   sup: 0.544  subsetsup: 0.596\n",
      "{' Private', ' United-States'} ==> {' 0', ' White'}   0.880   sup: 0.544  subsetsup: 0.618\n",
      "{' Private', ' 0', ' White'} ==> {' United-States'}   0.914   sup: 0.544  subsetsup: 0.596\n",
      "{' Private', ' 0', ' United-States'} ==> {' White'}   0.880   sup: 0.544  subsetsup: 0.618\n",
      "{' Private', ' White', ' United-States'} ==> {' 0'}   1.000   sup: 0.544  subsetsup: 0.544\n",
      "{' Private', ' Male'} ==> {' 0', ' White', ' United-States'}   0.800   sup: 0.367  subsetsup: 0.459\n",
      "{' Private', ' 0', ' Male'} ==> {' White', ' United-States'}   0.800   sup: 0.367  subsetsup: 0.459\n",
      "{' Private', ' White', ' Male'} ==> {' 0', ' United-States'}   0.911   sup: 0.367  subsetsup: 0.403\n",
      "{' Private', ' Male', ' United-States'} ==> {' 0', ' White'}   0.905   sup: 0.367  subsetsup: 0.406\n",
      "{' Private', ' 0', ' White', ' Male'} ==> {' United-States'}   0.911   sup: 0.367  subsetsup: 0.403\n",
      "{' Private', ' 0', ' Male', ' United-States'} ==> {' White'}   0.905   sup: 0.367  subsetsup: 0.406\n",
      "{' Private', ' White', ' Male', ' United-States'} ==> {' 0'}   1.000   sup: 0.367  subsetsup: 0.367\n",
      "{' <=50K', ' White'} ==> {' 0', ' United-States'}   0.914   sup: 0.581  subsetsup: 0.636\n",
      "{' <=50K', ' United-States'} ==> {' 0', ' White'}   0.860   sup: 0.581  subsetsup: 0.676\n",
      "{' 0', ' White', ' <=50K'} ==> {' United-States'}   0.914   sup: 0.581  subsetsup: 0.636\n",
      "{' 0', ' United-States', ' <=50K'} ==> {' White'}   0.860   sup: 0.581  subsetsup: 0.676\n",
      "{' <=50K', ' White', ' United-States'} ==> {' 0'}   1.000   sup: 0.581  subsetsup: 0.581\n",
      "{' <=50K', ' White', ' Male'} ==> {' 0', ' United-States'}   0.910   sup: 0.366  subsetsup: 0.402\n",
      "{' <=50K', ' Male', ' United-States'} ==> {' 0', ' White'}   0.890   sup: 0.366  subsetsup: 0.411\n",
      "{' 0', ' White', ' Male', ' <=50K'} ==> {' United-States'}   0.910   sup: 0.366  subsetsup: 0.402\n",
      "{' 0', ' Male', ' United-States', ' <=50K'} ==> {' White'}   0.890   sup: 0.366  subsetsup: 0.411\n",
      "{' <=50K', ' White', ' Male', ' United-States'} ==> {' 0'}   1.000   sup: 0.366  subsetsup: 0.366\n",
      "{' Private', ' <=50K', ' White'} ==> {' 0', ' United-States'}   0.905   sup: 0.413  subsetsup: 0.457\n",
      "{' Private', ' <=50K', ' United-States'} ==> {' 0', ' White'}   0.863   sup: 0.413  subsetsup: 0.479\n",
      "{' Private', ' 0', ' White', ' <=50K'} ==> {' United-States'}   0.905   sup: 0.413  subsetsup: 0.457\n",
      "{' Private', ' 0', ' United-States', ' <=50K'} ==> {' White'}   0.863   sup: 0.413  subsetsup: 0.479\n",
      "{' Private', ' <=50K', ' White', ' United-States'} ==> {' 0'}   1.000   sup: 0.413  subsetsup: 0.413\n"
     ]
    }
   ],
   "source": [
    "rules = associationRule(freqItems, itemSetList, minConf)\n",
    "print('\\nRules:')\n",
    "for rule in rules:\n",
    "    print('{} ==> {}   {:.3f}   sup: {:.3f}  subsetsup: {:.3f}'.format(rule[0], rule[1], rule[2], rule[3] / len(itemSetList), rule[4] / len(itemSetList)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from mlxtend.frequent_patterns import fpgrowth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyfpgrowth in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyfpgrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfpgrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = pyfpgrowth. find_frequent_patterns(itemSetList, 19536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = pyfpgrowth. generate_association_rules(patterns,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(' Male',): 21790,\n",
       " (' 0', ' Male'): 40341,\n",
       " (' Private', ' United-States'): 20135,\n",
       " (' 0', ' Private', ' United-States'): 37795,\n",
       " (' 0', ' Private'): 42678,\n",
       " (' 0', ' 0', ' Private'): 19982,\n",
       " (' <=50K', ' White'): 20699,\n",
       " (' 0', ' <=50K', ' White'): 39860,\n",
       " (' <=50K', ' United-States'): 21999,\n",
       " (' 0', ' <=50K', ' United-States'): 42393,\n",
       " (' 0', ' <=50K'): 47659,\n",
       " (' 0', ' 0', ' <=50K'): 22939,\n",
       " (' United-States', ' White'): 25621,\n",
       " (' 0', ' United-States', ' White'): 47718,\n",
       " (' 0', ' White'): 51877,\n",
       " (' 0', ' 0', ' White'): 24061,\n",
       " (' United-States',): 29170,\n",
       " (' 0', ' United-States'): 54490,\n",
       " (' 0',): 60891,\n",
       " (' 0', ' 0'): 28330}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(' Male',): ((' 0',), 1.8513538320330427),\n",
       " (' United-States',): ((' 0',), 1.868015083990401),\n",
       " (' 0', ' Private'): ((' United-States',), 0.8855850789634003),\n",
       " (' Private', ' United-States'): ((' 0',), 1.8770797119443754),\n",
       " (' 0', ' <=50K'): ((' United-States',), 0.8895067038754485),\n",
       " (' <=50K', ' White'): ((' 0',), 1.9256968935697376),\n",
       " (' <=50K', ' United-States'): ((' 0',), 1.9270421382790126),\n",
       " (' 0', ' 0'): ((' White',), 0.8493116837274973),\n",
       " (' 0', ' United-States'): ((' White',), 0.8757203156542485),\n",
       " (' 0', ' White'): ((' United-States',), 0.9198295969312027),\n",
       " (' United-States', ' White'): ((' 0',), 1.862456578587877),\n",
       " (' 0',): ((' United-States',), 0.8948777323413969)}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.19.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (1.21.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (45.2.0.post20200210)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (3.4.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (1.3.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (0.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from mlxtend) (0.22.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (7.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2019.3)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.0.0->mlxtend) (1.14.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frequent itemsets are:\n",
      "\n",
      "('Married-civ-spouse_5', 'White_8')\n",
      "('Married-civ-spouse_5', 'Male_9')\n",
      "('Married-civ-spouse_5', '0_10')\n",
      "('Married-civ-spouse_5', '0_11')\n",
      "('Married-civ-spouse_5', 'United-States_13')\n",
      "('White_8', 'Male_9')\n",
      "('White_8', '0_10')\n",
      "('White_8', '0_11')\n",
      "('White_8', 'United-States_13')\n",
      "('White_8', '<=50K\\n_14')\n",
      "('White_8', 'Private_1')\n",
      "('White_8', '40_12')\n",
      "('Male_9', '0_10')\n",
      "('Male_9', '0_11')\n",
      "('Male_9', 'United-States_13')\n",
      "('Male_9', '<=50K\\n_14')\n",
      "('Male_9', 'Private_1')\n",
      "('0_10', '0_11')\n",
      "('0_10', 'United-States_13')\n",
      "('0_10', '<=50K\\n_14')\n",
      "('0_10', 'Private_1')\n",
      "('0_10', '40_12')\n",
      "('0_11', 'United-States_13')\n",
      "('0_11', '<=50K\\n_14')\n",
      "('0_11', 'Private_1')\n",
      "('0_11', '40_12')\n",
      "('United-States_13', '<=50K\\n_14')\n",
      "('United-States_13', 'Private_1')\n",
      "('United-States_13', '40_12')\n",
      "('<=50K\\n_14', 'Private_1')\n",
      "('<=50K\\n_14', '40_12')\n",
      "('Married-civ-spouse_5', 'White_8', '0_10')\n",
      "('Married-civ-spouse_5', 'White_8', 'United-States_13')\n",
      "('Married-civ-spouse_5', 'Male_9', '0_10')\n",
      "('Married-civ-spouse_5', 'Male_9', 'United-States_13')\n",
      "('Married-civ-spouse_5', '0_10', '0_11')\n",
      "('White_8', 'Male_9', '0_11')\n",
      "('White_8', 'Male_9', '<=50K\\n_14')\n",
      "('White_8', '0_10', 'United-States_13')\n",
      "('White_8', '0_10', 'Private_1')\n",
      "('White_8', '0_11', 'United-States_13')\n",
      "('White_8', '0_11', 'Private_1')\n",
      "('White_8', 'United-States_13', '<=50K\\n_14')\n",
      "('Male_9', '0_10', '0_11')\n",
      "('Male_9', '0_10', '<=50K\\n_14')\n",
      "('Male_9', '0_11', '<=50K\\n_14')\n",
      "('Male_9', 'United-States_13', 'Private_1')\n",
      "('0_10', '0_11', '<=50K\\n_14')\n",
      "('0_10', '0_11', '40_12')\n",
      "('0_10', 'United-States_13', 'Private_1')\n",
      "('0_10', '<=50K\\n_14', 'Private_1')\n",
      "('0_11', 'United-States_13', 'Private_1')\n",
      "('0_11', '<=50K\\n_14', 'Private_1')\n",
      "('White_8', '0_10', 'United-States_13', '0_11')\n",
      "('White_8', '0_10', 'United-States_13', 'Private_1')\n",
      "('White_8', '0_10', 'Male_9', '0_11')\n",
      "('White_8', '0_10', 'Male_9', '<=50K\\n_14')\n",
      "('White_8', '0_10', 'Male_9', 'Private_1')\n",
      "('White_8', '0_10', '0_11', '<=50K\\n_14')\n",
      "('White_8', '0_10', '0_11', 'Private_1')\n",
      "('White_8', '0_10', '<=50K\\n_14', 'Private_1')\n",
      "('White_8', 'United-States_13', 'Male_9', '0_11')\n",
      "('White_8', 'United-States_13', 'Male_9', '<=50K\\n_14')\n",
      "('White_8', 'United-States_13', 'Male_9', 'Private_1')\n",
      "('White_8', 'United-States_13', '0_11', '<=50K\\n_14')\n",
      "('White_8', 'United-States_13', '0_11', 'Private_1')\n",
      "('White_8', 'Male_9', '0_11', 'Private_1')\n",
      "('White_8', '0_11', '<=50K\\n_14', 'Private_1')\n",
      "('0_10', 'United-States_13', 'Male_9', '0_11')\n",
      "('0_10', 'United-States_13', 'Male_9', '<=50K\\n_14')\n",
      "('0_10', 'United-States_13', 'Male_9', 'Private_1')\n",
      "('0_10', 'United-States_13', '0_11', '<=50K\\n_14')\n",
      "('0_10', 'United-States_13', '0_11', 'Private_1')\n",
      "('0_10', 'United-States_13', '0_11', '40_12')\n",
      "('0_10', 'United-States_13', '<=50K\\n_14', 'Private_1')\n",
      "('0_10', 'Male_9', '0_11', '<=50K\\n_14')\n",
      "('0_10', 'Male_9', '0_11', 'Private_1')\n",
      "('United-States_13', 'Male_9', '0_11', '<=50K\\n_14')\n",
      "('United-States_13', 'Male_9', '0_11', 'Private_1')\n",
      "('United-States_13', '0_11', '<=50K\\n_14', 'Private_1')\n",
      "('White_8', '0_10', 'United-States_13', '0_11', 'Male_9')\n",
      "('White_8', '0_10', 'United-States_13', 'Private_1', '<=50K\\n_14')\n",
      "('White_8', '0_10', '0_11', 'Private_1', '<=50K\\n_14')\n",
      "('White_8', '0_10', '0_11', 'Male_9', '<=50K\\n_14')\n",
      "('0_10', 'United-States_13', '0_11', 'Private_1', '<=50K\\n_14')\n",
      "('0_10', 'United-States_13', '0_11', 'Male_9', '<=50K\\n_14')\n",
      "('White_8', '0_10', 'United-States_13', '0_11', 'Private_1', '<=50K\\n_14')\n",
      "\n",
      "\n",
      "The runtime for this algorithm(with a sampling factor of .6 and a min_supp = .6) is 4.754226922988892 seconds.\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "from itertools import combinations, chain\n",
    "from  more_itertools import unique_everseen\n",
    "#import sets\n",
    "import time\n",
    "import random\n",
    "#import data and preprocess\n",
    "data = open(\"testr.csv\",\"r\")\n",
    "\n",
    "#sampling improvement for Apriori\n",
    "samplingfactor = .6\n",
    "\n",
    "\n",
    "\n",
    "#input data and each observation as a list within a data list structure\n",
    "#add _i to data value indicating i'th variable\n",
    "def clean(dta,samplingfactor):\n",
    "    datalist = []\n",
    "    for line in dta:\n",
    "        linesep = line.split(\", \")\n",
    "        for attribute in linesep:\n",
    "            newattribute = attribute  + \"_\" + str(linesep.index(attribute))\n",
    "            linesep[linesep.index(attribute)] = newattribute\n",
    "        datalist.append(linesep)\n",
    "\n",
    "    random.shuffle(datalist) #randomizes data order\n",
    "    datalist = [datalist[i] for i in range(0,int(round(samplingfactor*len(datalist))))] #return the first sampfactor\n",
    "    return datalist\n",
    "\n",
    "\n",
    "\n",
    "#Obtaining C1 - counts of all variable values\n",
    "def gen_C1(dta):\n",
    "    count_dict = {}\n",
    "    for observation in dta:\n",
    "        for val in observation:\n",
    "\n",
    "            #if value in observation is not in dictionary, start its count at 1\n",
    "            #if it is in the dictionary then increment its count by 1\n",
    "\n",
    "            if val not in count_dict:\n",
    "                count_dict[val]= 1\n",
    "            elif val in count_dict:\n",
    "                count_dict[val] += 1\n",
    "\n",
    "    return count_dict\n",
    "\n",
    "\n",
    "#Obtaining L1\n",
    "def gen_L1(dict,min_supp,samplingfactor):\n",
    "    L1 = []\n",
    "    for var in dict:\n",
    "\n",
    "        #if a value in the count dictionary passes the minimum support threshold\n",
    "        #add it to list\n",
    "        if float(dict[var])/float(nobservations) > min_supp*samplingfactor:\n",
    "            L1.append(var)\n",
    "\n",
    "    return L1\n",
    "\n",
    "\n",
    "#print nobservations\n",
    "\n",
    "\n",
    "#check if k-1 subset of k itemset is in L_k-1\n",
    "def has_infeq_subsets(k,L,c):\n",
    "    for i in list(combinations(c,k-1)):\n",
    "            if i not in L:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "\n",
    "#generate C2 from L1\n",
    "def gen_C2(k,L):\n",
    "    Ck = list(combinations(L,k)) #all combinations of 2 itemsets\n",
    "    for c in Ck:\n",
    "        if has_infeq_subsets(k,L,c):\n",
    "            Ck.remove(c) #if it has infrequent subsets then remove candidate\n",
    "        else:\n",
    "            pass\n",
    "    return Ck\n",
    "\n",
    "\n",
    "def gen_Lk(Ck,min_supp,dta,samplingfactor):\n",
    "    countdict = {}\n",
    "    for c in Ck:\n",
    "        countdict[c] = 0 #start every candidate count at 0\n",
    "\n",
    "    for observation in dta:\n",
    "        for c in Ck:\n",
    "            if set(c).issubset(observation):\n",
    "                countdict[c] += 1 #if candidate is subset of observation, increment count\n",
    "\n",
    "    Lk = []\n",
    "    for c in Ck:\n",
    "        if float(countdict[c])/nobservations > min_supp*samplingfactor:\n",
    "            Lk.append(c) #if minimum support threshold is passed append to list\n",
    "\n",
    "    return Lk\n",
    "\n",
    "#generate candidates for k > 2\n",
    "#flatten tuples, get all possible combinations, and prune\n",
    "def gen_Ck(k,L):\n",
    "    flatten = [item for subtuple in L for item in subtuple] #flattens all candidates\n",
    "    uniqueflatten = list(unique_everseen(flatten)) #gets out duplicate candidates\n",
    "    Ck = list(combinations(uniqueflatten,k)) #creates list of all possible combinations of k length\n",
    "    for c in Ck:\n",
    "        if has_infeq_subsets(k,L,c):\n",
    "            Ck.remove(c)\n",
    "        else:\n",
    "            pass\n",
    "    return Ck\n",
    "\n",
    "\n",
    "#Apriori Algorithm method\n",
    "def Apriori(k,L,dta,min_supp,samplingfactor):\n",
    "    l_of_L = [] #to store different Lk's\n",
    "    while L != []: #while there are frequent itemsets\n",
    "        if k == 2:\n",
    "            Ck = gen_C2(k,L) #use specific 2-tuple candidate generator\n",
    "        else:\n",
    "            Ck = gen_Ck(k,L) #otherwise use normal one\n",
    "        L = gen_Lk(Ck,min_supp,cleandata,samplingfactor)\n",
    "        l_of_L.append(L)\n",
    "        k += 1\n",
    "\n",
    "    return l_of_L[0:len(l_of_L)-1] #return all Lk stored that are non-empty\n",
    "\n",
    "\n",
    "###Test###\n",
    "\n",
    "time1 = time.time()\n",
    "\n",
    "cleandata = clean(data,samplingfactor)\n",
    "\n",
    "#number of observations, used later for min_supp testing\n",
    "nobservations = len(cleandata)\n",
    "\n",
    "#getfirst candidate set\n",
    "C1 = gen_C1(cleandata)\n",
    "\n",
    "#generate L1\n",
    "L1 = gen_L1(C1,.75,samplingfactor)\n",
    "freqsets = Apriori(2,L1,cleandata,.6,samplingfactor)\n",
    "\n",
    "print(\"The frequent itemsets are:\" + \"\\n\")\n",
    "for i in freqsets:\n",
    "    for j in i:\n",
    "        print(j)\n",
    "\n",
    "time2 = time.time()\n",
    "\n",
    "testtime = time2 - time1\n",
    "print(\"\\n\")\n",
    "print(\"The runtime for this algorithm(with a sampling factor of .6 and a min_supp = .6) is\" + \" \" + str(testtime) + \" seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEst one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-a7c1ec7e880d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mApriori\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_sup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintitembysup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-129-a7c1ec7e880d>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mC1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_C1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0mLk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprunestep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-129-a7c1ec7e880d>\u001b[0m in \u001b[0;36mfind_C1\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_C1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mC1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m             \u001b[0mrowi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrozenset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrowi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-129-a7c1ec7e880d>\u001b[0m in \u001b[0;36m_readFile\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'age:'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'workclass:'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                 \u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'fnlwgt:'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'education:'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct 12 10:50:51 2016\n",
    "@author: nancynan\n",
    "\"\"\"\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import time\n",
    "#os.system('clear')\n",
    "\n",
    "class Apriori:\n",
    "    \n",
    "    \n",
    "    def __init__(self, input_file, min_sup):\n",
    "        self.input_file = input_file\n",
    "        self.min_sup = min_sup\n",
    "        self.translist = []\n",
    "        self.items_with_sup = []\n",
    "        self.freqset = defaultdict(int)\n",
    "        self.enlarged = {}\n",
    "    \n",
    "    def _readFile(self):\n",
    "        with open(self.input_file, 'rU') as f:\n",
    "            for line in f:\n",
    "                #print(line)\n",
    "                lines = line.strip().split(',')\n",
    "                lines[0] = 'age:'+lines[0]\n",
    "                lines[1] = 'workclass:'+lines[1]\n",
    "                lines[2] = 'fnlwgt:'+lines[2]\n",
    "                lines[3] = 'education:'+lines[3]\n",
    "                lines[4] = 'ed_num:'+lines[4]\n",
    "                lines[5] = 'marital-status:'+lines[5]\n",
    "                lines[6] = 'occupation:'+lines[6]\n",
    "                lines[7] = 'relationship:'+lines[7]\n",
    "                lines[8] = 'race:'+lines[8]\n",
    "                lines[9] = 'sex:'+lines[9]\n",
    "                lines[10] = 'capital-gain:'+lines[10]\n",
    "                lines[11] = 'capital-loss:'+lines[11]\n",
    "                lines[12] = 'hrs-per-week:'+lines[12]\n",
    "                lines[13] = 'native-country:'+lines[13]\n",
    "                lines[14] = 'salary:'+lines[14]\n",
    "                yield lines\n",
    "                \n",
    "    def find_C1(self):\n",
    "        C1=set()\n",
    "        for row in self._readFile():\n",
    "            rowi=frozenset(row)\n",
    "            self.translist.append(rowi)\n",
    "            for i in rowi:\n",
    "                C1.add(frozenset([i]))\n",
    "        return C1\n",
    "                    \n",
    "    \n",
    "    def prunestep(self,C):\n",
    "        L=set()\n",
    "        freqsetloc = defaultdict(int)\n",
    "\n",
    "        for item in C:\n",
    "            for trans in self.translist:\n",
    "                if item.issubset(trans):\n",
    "                    self.freqset[item]+=1\n",
    "                    freqsetloc[item]+=1\n",
    "        for key,value in freqsetloc.items():\n",
    "            support=float(value)/len(self.translist)\n",
    "            if support>=min_sup:\n",
    "                L.add(key)\n",
    "        return L\n",
    "        \n",
    "    def Support(self, item):\n",
    "        return float(self.freqset[item]) / len(self.translist)    \n",
    "        \n",
    "    def joinstep(self, itemset, length):\n",
    "        Ck=set()\n",
    "        for i in itemset:\n",
    "            for j in itemset:\n",
    "                joinres=i.union(j)\n",
    "                if len(joinres)==length:\n",
    "                    Ck.add(joinres)\n",
    "        return Ck\n",
    "                \n",
    "    def run(self):\n",
    "        C1=self.find_C1()\n",
    "        Lk=self.prunestep(C1)\n",
    "        k=2\n",
    "        empset=set([])\n",
    "\n",
    "        while (Lk!=empset):\n",
    "            self.enlarged[k-1]=Lk\n",
    "            nextC=self.joinstep(Lk,k)\n",
    "            nextL=self.prunestep(nextC)\n",
    "            Lk=nextL\n",
    "            k+=1\n",
    "            \n",
    "        for value in self.enlarged.values():\n",
    "            for item in value:\n",
    "                self.items_with_sup.append(\n",
    "                (tuple(item), self.Support(item)))\n",
    "                    \n",
    "    def printitembysup(self):\n",
    "            i = 1\n",
    "            for item, support in sorted(\n",
    "            self.items_with_sup, key=lambda i: i[1],\n",
    "            reverse=True):\n",
    "                print ('Item %d: %s, Support: %.3f' % (i, str(item), support))\n",
    "                i += 1\n",
    "            \n",
    "    def writefreqpat(self):\n",
    "        with open('apriori_output.csv', 'w') as f:\n",
    "            for item, support in sorted(\n",
    "            self.items_with_sup, key=lambda i: i[1],\n",
    "            reverse=True):\n",
    "                f.write('%.3f, %s\\n' % (support, ','.join(item)))\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "#    begin1=time.time()\n",
    "    input_file = 'testr.csv'\n",
    "    \n",
    "    #!!you can change into any number in (0,1)\n",
    "    min_sup = 0.5\n",
    "\n",
    "    a = Apriori(input_file, min_sup)\n",
    "    a.run()\n",
    "    a.printitembysup()\n",
    "\n",
    "    # !!add # below if don't want csv file\n",
    "    a.writefreqpat()\n",
    "#    stop1=time.time()\n",
    "#    print ('apriori takes',(stop1-begin1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 1: ('capital-loss: 0',), Support: 0.953\n",
      "Item 2: ('capital-gain: 0',), Support: 0.917\n",
      "Item 3: ('native-country: United-States',), Support: 0.896\n",
      "Item 4: ('capital-gain: 0', 'capital-loss: 0'), Support: 0.870\n",
      "Item 5: ('race: White',), Support: 0.854\n",
      "Item 6: ('native-country: United-States', 'capital-loss: 0'), Support: 0.854\n",
      "Item 7: ('native-country: United-States', 'capital-gain: 0'), Support: 0.820\n",
      "Item 8: ('race: White', 'capital-loss: 0'), Support: 0.813\n",
      "Item 9: ('race: White', 'native-country: United-States'), Support: 0.787\n",
      "Item 10: ('race: White', 'capital-gain: 0'), Support: 0.780\n",
      "Item 11: ('native-country: United-States', 'capital-gain: 0', 'capital-loss: 0'), Support: 0.778\n",
      "Item 12: (' <=50K',), Support: 0.759\n",
      "Item 13: ('race: White', 'native-country: United-States', 'capital-loss: 0'), Support: 0.748\n",
      "Item 14: ('race: White', 'capital-gain: 0', 'capital-loss: 0'), Support: 0.739\n",
      "Item 15: (' <=50K', 'capital-loss: 0'), Support: 0.736\n",
      "Item 16: (' <=50K', 'capital-gain: 0'), Support: 0.727\n",
      "Item 17: ('race: White', 'native-country: United-States', 'capital-gain: 0'), Support: 0.718\n",
      "Item 18: (' <=50K', 'capital-gain: 0', 'capital-loss: 0'), Support: 0.704\n",
      "Item 19: ('workclass: Private',), Support: 0.697\n",
      "Item 20: ('native-country: United-States', 'capital-gain: 0', 'race: White', 'capital-loss: 0'), Support: 0.679\n",
      "Item 21: ('native-country: United-States', ' <=50K'), Support: 0.676\n",
      "Item 22: ('sex: Male',), Support: 0.669\n",
      "Item 23: ('capital-loss: 0', 'workclass: Private'), Support: 0.667\n",
      "Item 24: (' <=50K', 'capital-loss: 0', 'native-country: United-States'), Support: 0.655\n",
      "Item 25: ('native-country: United-States', 'capital-gain: 0', ' <=50K'), Support: 0.647\n",
      "Item 26: ('capital-gain: 0', 'workclass: Private'), Support: 0.644\n",
      "Item 27: ('race: White', ' <=50K'), Support: 0.636\n",
      "Item 28: ('sex: Male', 'capital-loss: 0'), Support: 0.634\n",
      "Item 29: ('native-country: United-States', 'capital-gain: 0', ' <=50K', 'capital-loss: 0'), Support: 0.626\n",
      "Item 30: ('native-country: United-States', 'workclass: Private'), Support: 0.618\n",
      "Item 31: ('race: White', ' <=50K', 'capital-loss: 0'), Support: 0.616\n",
      "Item 32: ('capital-gain: 0', 'capital-loss: 0', 'workclass: Private'), Support: 0.614\n",
      "Item 33: ('race: White', ' <=50K', 'capital-gain: 0'), Support: 0.608\n",
      "Item 34: ('sex: Male', 'capital-gain: 0'), Support: 0.605\n",
      "Item 35: ('native-country: United-States', 'sex: Male'), Support: 0.599\n",
      "Item 36: ('race: White', 'workclass: Private'), Support: 0.596\n",
      "Item 37: ('native-country: United-States', 'capital-loss: 0', 'workclass: Private'), Support: 0.591\n",
      "Item 38: ('race: White', 'sex: Male'), Support: 0.589\n",
      "Item 39: ('capital-gain: 0', 'race: White', ' <=50K', 'capital-loss: 0'), Support: 0.588\n",
      "Item 40: ('race: White', ' <=50K', 'native-country: United-States'), Support: 0.581\n",
      "Item 41: ('native-country: United-States', 'capital-gain: 0', 'workclass: Private'), Support: 0.570\n",
      "Item 42: ('sex: Male', 'capital-gain: 0', 'capital-loss: 0'), Support: 0.570\n",
      "Item 43: ('race: White', 'capital-loss: 0', 'workclass: Private'), Support: 0.569\n",
      "Item 44: ('capital-loss: 0', 'native-country: United-States', 'sex: Male'), Support: 0.567\n",
      "Item 45: ('native-country: United-States', 'race: White', ' <=50K', 'capital-loss: 0'), Support: 0.562\n",
      "Item 46: ('race: White', 'sex: Male', 'capital-loss: 0'), Support: 0.557\n",
      "Item 47: ('native-country: United-States', 'capital-gain: 0', 'race: White', ' <=50K'), Support: 0.556\n",
      "Item 48: ('race: White', 'capital-gain: 0', 'workclass: Private'), Support: 0.549\n",
      "Item 49: (' <=50K', 'workclass: Private'), Support: 0.545\n",
      "Item 50: ('race: White', 'native-country: United-States', 'workclass: Private'), Support: 0.544\n",
      "Item 51: ('native-country: United-States', 'capital-gain: 0', 'workclass: Private', 'capital-loss: 0'), Support: 0.542\n",
      "Item 52: ('race: White', 'native-country: United-States', 'sex: Male'), Support: 0.542\n",
      "Item 53: ('sex: Male', 'capital-gain: 0', 'native-country: United-States'), Support: 0.540\n",
      "Item 54: ('native-country: United-States', 'capital-gain: 0', 'race: White', 'capital-loss: 0', ' <=50K'), Support: 0.537\n",
      "Item 55: ('race: White', 'sex: Male', 'capital-gain: 0'), Support: 0.531\n",
      "Item 56: (' <=50K', 'capital-loss: 0', 'workclass: Private'), Support: 0.529\n",
      "Item 57: (' <=50K', 'capital-gain: 0', 'workclass: Private'), Support: 0.523\n",
      "Item 58: ('capital-gain: 0', 'workclass: Private', 'race: White', 'capital-loss: 0'), Support: 0.522\n",
      "Item 59: ('native-country: United-States', 'workclass: Private', 'race: White', 'capital-loss: 0'), Support: 0.519\n",
      "Item 60: ('native-country: United-States', 'sex: Male', 'race: White', 'capital-loss: 0'), Support: 0.512\n",
      "Item 61: ('sex: Male', 'capital-gain: 0', 'native-country: United-States', 'capital-loss: 0'), Support: 0.508\n",
      "Item 62: ('capital-gain: 0', 'workclass: Private', ' <=50K', 'capital-loss: 0'), Support: 0.508\n",
      "Item 63: ('native-country: United-States', 'capital-gain: 0', 'workclass: Private', 'race: White'), Support: 0.500\n",
      "imroved_fp takes 108.88062453269958\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct 19 10:50:51 2016\n",
    "\n",
    "@author: nancynan\n",
    "\"\"\"\n",
    "#import sys\n",
    "from collections import defaultdict\n",
    "#import os\n",
    "import time\n",
    "#os.system('clear')\n",
    "\n",
    "class Apriori:\n",
    "    \n",
    "    \n",
    "    def __init__(self, input_file, min_sup):\n",
    "        self.input_file = input_file\n",
    "        self.min_sup = min_sup\n",
    "        self.translist = []\n",
    "        self.items_with_sup = []\n",
    "        self.freqset = defaultdict(int)\n",
    "        self.enlarged = {}\n",
    "        self.L1_count = {} \n",
    "        self.L1_TID = {}\n",
    "    \n",
    "    def _readFile(self):\n",
    "        with open(self.input_file, 'rU') as f:\n",
    "            for line in f:\n",
    "#                print(line)\n",
    "                lines = line.strip().split(',')\n",
    "                lines[0] = 'age:'+lines[0]\n",
    "                lines[1] = 'workclass:'+lines[1]\n",
    "                lines[2] = 'fnlwgt:'+lines[2]\n",
    "                lines[3] = 'education:'+lines[3]\n",
    "                lines[4] = 'ed_num:'+lines[4]\n",
    "                lines[5] = 'marital-status:'+lines[5]\n",
    "                lines[6] = 'occupation:'+lines[6]\n",
    "                lines[7] = 'relationship:'+lines[7]\n",
    "                lines[8] = 'race:'+lines[8]\n",
    "                lines[9] = 'sex:'+lines[9]\n",
    "                lines[10] = 'capital-gain:'+lines[10]\n",
    "                lines[11] = 'capital-loss:'+lines[11]\n",
    "                lines[12] = 'hrs-per-week:'+lines[12]\n",
    "                lines[13] = 'native-country:'+lines[13]\n",
    "                yield lines\n",
    "                \n",
    "    def find_C1(self):\n",
    "        C1=set()\n",
    "        tid=0\n",
    "        for row in self._readFile():\n",
    "            rowi=frozenset(row)\n",
    "            self.translist.append(rowi)\n",
    "            tid += 1\n",
    "            for i in rowi:\n",
    "                C1.add(frozenset([i]))\n",
    "                if i not in self.L1_TID:\n",
    "                    self.L1_TID[i]=set([tid])\n",
    "                else:\n",
    "                    self.L1_TID[i].add(tid)\n",
    "        return C1\n",
    "                    \n",
    "    \n",
    "    def prunestep(self,C):\n",
    "        L=set()\n",
    "        freqsetloc = defaultdict(int)\n",
    "\n",
    "        for item in C:\n",
    "            if all(x in self.L1_count for x in list(item)):\n",
    "                min_item = self.findMinItem(item)\n",
    "                # TID:list of transaaction IDs for min_item\n",
    "                TID = self.L1_TID[min_item]\n",
    "                # only scan those with id in TID\n",
    "                for index in TID:\n",
    "                    if item.issubset(self.translist[index-1]):\n",
    "                        self.freqset[item] += 1\n",
    "                        freqsetloc[item] += 1\n",
    "        for key,value in freqsetloc.items():\n",
    "            support=float(value)/len(self.translist)\n",
    "            if support>=min_sup:\n",
    "                L.add(key)\n",
    "        return L\n",
    "        \n",
    "    def findMinItem(self, items):\n",
    "        # split into single item and return them with min_sup\n",
    "        minimum =100000\n",
    "        for key,value in self.L1_count.items():\n",
    "            if key in items and value < minimum:\n",
    "                minimum = value\n",
    "        for key,value in self.L1_count.items():\n",
    "            if value == minimum:\n",
    "                return key \n",
    "\n",
    "    def getL1Count(self, C1):\n",
    "        # for content of dictionary L1_count\n",
    "        local_set = defaultdict(int)\n",
    "        for item in C1:\n",
    "            for rowi in self.translist:\n",
    "                if item.issubset(rowi):\n",
    "                    local_set[item] += 1\n",
    "        for item, count in local_set.items():\n",
    "            support = float(count)/len(self.translist)\n",
    "            if support >= min_sup:\n",
    "                key = [k for k in item][0]\n",
    "                self.L1_count[key]=count\n",
    "        return \n",
    "        \n",
    "    def Support(self, item):\n",
    "        return float(self.freqset[item]) / len(self.translist)    \n",
    "        \n",
    "    def joinstep(self, itemset, length):\n",
    "        Ck=set()\n",
    "        for i in itemset:\n",
    "            for j in itemset:\n",
    "                joinres=i.union(j)\n",
    "                if len(joinres)==length:\n",
    "                    Ck.add(joinres)\n",
    "        return Ck\n",
    "                \n",
    "    def run(self):\n",
    "        C1=self.find_C1()\n",
    "        self.getL1Count(C1)\n",
    "        Lk=self.prunestep(C1)\n",
    "        k=2\n",
    "        empset=set([])\n",
    "\n",
    "        while (Lk!=empset):\n",
    "            self.enlarged[k-1]=Lk\n",
    "            nextC=self.joinstep(Lk,k)\n",
    "            nextL=self.prunestep(nextC)\n",
    "            Lk=nextL\n",
    "            k+=1\n",
    "            \n",
    "        for value in self.enlarged.values():\n",
    "            for item in value:\n",
    "                self.items_with_sup.append(\n",
    "                (tuple(item), self.Support(item)))\n",
    "                    \n",
    "    def printitembysup(self):\n",
    "            i = 1\n",
    "            for item, support in sorted(\n",
    "            self.items_with_sup, key=lambda i: i[1],\n",
    "            reverse=True):\n",
    "                print ('Item %d: %s, Support: %.3f' % (i, str(item), support))\n",
    "                i += 1\n",
    "            \n",
    "    def writefreqpat(self):\n",
    "        with open('improved_apriori_output.csv', 'w') as f:\n",
    "            for item, support in sorted(\n",
    "                self.items_with_sup, key=lambda i: i[1],\n",
    "                reverse=True):\n",
    "                f.write('%.3f, %s\\n' % (support, ','.join(item)))\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    begin1=time.time()\n",
    "    input_file = 'adult_data.csv'\n",
    "    \n",
    "    #!!you can change into any number in (0,1)\n",
    "    min_sup = 0.5\n",
    "\n",
    "    a = Apriori(input_file, min_sup)\n",
    "    a.run()\n",
    "    a.printitembysup()\n",
    "\n",
    "    # !!add # below if don't want csv file\n",
    "    a.writefreqpat()\n",
    "    stop1=time.time()\n",
    "    print ('imroved_fp takes',(stop1-begin1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:140: DeprecationWarning: 'U' mode is deprecated\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-91a46f9db045>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    151\u001b[0m      \u001b[0mminConfidence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m      \u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrules\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunApriori\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minFile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminSupport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminConfidence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m      \u001b[0mprintResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrules\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-173-91a46f9db045>\u001b[0m in \u001b[0;36mrunApriori\u001b[1;34m(data_iter, minSupport, minConfidence)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;31m# Dictionary which stores Association Rules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0moneCSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturnItemsWithMinSupport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitemSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransactionList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminSupport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreqSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mcurrentLSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moneCSet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-173-91a46f9db045>\u001b[0m in \u001b[0;36mreturnItemsWithMinSupport\u001b[1;34m(itemSet, transactionList, minSupport, freqSet)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitemSet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtransaction\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransactionList\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransaction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m                 \u001b[0mfreqSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mlocalSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Oct 3, 03:09:11 2021\n",
    "\n",
    "@author: ayushi\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "APRIORI ALGORITHM\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def subsets(arr):\n",
    "    \"\"\" Returns non empty subsets of arr\"\"\"\n",
    "    return chain(*[combinations(arr, i + 1) for i, a in enumerate(arr)])\n",
    "\n",
    "def returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet):\n",
    "    \"\"\"calculates the support for items in the itemSet and returns a subset\n",
    "    of the itemSet each of whose elements satisfies the minimum support\"\"\"\n",
    "    _itemSet = set()\n",
    "    localSet = defaultdict(int)\n",
    "\n",
    "    for item in itemSet:\n",
    "        for transaction in transactionList:\n",
    "            if item.issubset(transaction):\n",
    "                freqSet[item] += 1\n",
    "                localSet[item] += 1\n",
    "\n",
    "    for item, count in localSet.items():\n",
    "        support = float(count) / len(transactionList)\n",
    "\n",
    "        if support >= minSupport:\n",
    "            _itemSet.add(item)\n",
    "\n",
    "    return _itemSet\n",
    "\n",
    "\n",
    "def joinSet(itemSet, length):\n",
    "    \"\"\"Join a set with itself and returns the n-element itemsets\"\"\"\n",
    "    return set(\n",
    "        [i.union(j) for i in itemSet for j in itemSet if len(i.union(j)) == length]\n",
    "    )\n",
    "\n",
    "\n",
    "def getItemSetTransactionList(data_iterator):\n",
    "    transactionList = list()\n",
    "    itemSet = set()\n",
    "    for record in data_iterator:\n",
    "        transaction = frozenset(record)\n",
    "        transactionList.append(transaction)\n",
    "        for item in transaction:\n",
    "            itemSet.add(frozenset([item]))  # Generate 1-itemSets\n",
    "    return itemSet, transactionList\n",
    "\n",
    "\n",
    "def runApriori(data_iter, minSupport, minConfidence):\n",
    "    \"\"\"\n",
    "    run the apriori algorithm. data_iter is a record iterator\n",
    "    Return both:\n",
    "     - items (tuple, support)\n",
    "     - rules ((pretuple, posttuple), confidence)\n",
    "    \"\"\"\n",
    "    itemSet, transactionList = getItemSetTransactionList(data_iter)\n",
    "\n",
    "    freqSet = defaultdict(int)\n",
    "    largeSet = dict()\n",
    "    # Global dictionary which stores (key=n-itemSets,value=support)\n",
    "    # which satisfy minSupport\n",
    "\n",
    "    assocRules = dict()\n",
    "    # Dictionary which stores Association Rules\n",
    "\n",
    "    oneCSet = returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet)\n",
    "\n",
    "    currentLSet = oneCSet\n",
    "    k = 2\n",
    "    while currentLSet != set([]):\n",
    "        largeSet[k - 1] = currentLSet\n",
    "        currentLSet = joinSet(currentLSet, k)\n",
    "        currentCSet = returnItemsWithMinSupport(\n",
    "            currentLSet, transactionList, minSupport, freqSet\n",
    "        )\n",
    "        currentLSet = currentCSet\n",
    "        k = k + 1\n",
    "\n",
    "    def getSupport(item):\n",
    "        \"\"\"local function which Returns the support of an item\"\"\"\n",
    "        return float(freqSet[item]) / len(transactionList)\n",
    "\n",
    "    toRetItems = []\n",
    "    for key, value in largeSet.items():\n",
    "        toRetItems.extend([(tuple(item), getSupport(item)) for item in value])\n",
    "\n",
    "    toRetRules = []\n",
    "    for key, value in list(largeSet.items())[1:]:\n",
    "        for item in value:\n",
    "            _subsets = map(frozenset, [x for x in subsets(item)])\n",
    "            for element in _subsets:\n",
    "                remain = item.difference(element)\n",
    "                if len(remain) > 0:\n",
    "                    confidence = getSupport(item) / getSupport(element)\n",
    "                    if confidence >= minConfidence:\n",
    "                        toRetRules.append(((tuple(element), tuple(remain)), confidence))\n",
    "    return toRetItems, toRetRules\n",
    "\n",
    "\n",
    "def printResults(items, rules):\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    for item, support in sorted(items, key=lambda x: x[1]):\n",
    "        print(\"item: %s , %.3f\" % (str(item), support))\n",
    "    print(\"\\n------------------------ RULES:\")\n",
    "    for rule, confidence in sorted(rules, key=lambda x: x[1]):\n",
    "        pre, post = rule\n",
    "        print(\"Rule: %s ==> %s , %.3f\" % (str(pre), str(post), confidence))\n",
    "\n",
    "\n",
    "def to_str_results(items, rules):\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    i, r = [], []\n",
    "    for item, support in sorted(items, key=lambda x: x[1]):\n",
    "        x = \"item: %s , %.3f\" % (str(item), support)\n",
    "        i.append(x)\n",
    "\n",
    "    for rule, confidence in sorted(rules, key=lambda x: x[1]):\n",
    "        pre, post = rule\n",
    "        x = \"Rule: %s ==> %s , %.3f\" % (str(pre), str(post), confidence)\n",
    "        r.append(x)\n",
    "\n",
    "    return i, r\n",
    "\n",
    "\n",
    "def dataFromFile(fname):\n",
    "    \"\"\"Function which reads from the file and yields a generator\"\"\"\n",
    "    with open(fname, \"rU\") as file_iter:\n",
    "        for line in file_iter:\n",
    "            line = line.strip().rstrip(\",\")  # Remove trailing comma\n",
    "            record = frozenset(line.split(\",\"))\n",
    "            yield record\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "     inFile = dataFromFile('adult_data.csv')\n",
    "     minSupport = 0.6\n",
    "     minConfidence = 0.6\n",
    "     \n",
    "     items, rules = runApriori(inFile, minSupport, minConfidence)\n",
    "     printResults(items, rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
